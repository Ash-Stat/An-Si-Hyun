{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "데마실습과제1주차.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash-Stat/An-Si-Hyun/blob/data/%EB%8D%B0%EB%A7%88%EC%8B%A4%EC%8A%B5%EA%B3%BC%EC%A0%9C1%EC%A3%BC%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p2HcDl9lX-G"
      },
      "source": [
        "# RQ1. 과적합을 방지하고 비용을 줄이기 위한 효율적인 변수선택 및 데이터 축소방법\n",
        "\n",
        "바야흐로, 데이터의 홍수라고 불리우는 빅데이터의 시대가 도래했다.\n",
        "사실, 빅데이터의 시대에서는 데이터의 부족보다는 수 많은 잡음이 섞인 데이터셋 사이에서 예측 혹은 분석에 필요한 데이터만을 고르고 이에 맞는 피쳐를 엔지니어링 하는 기술이 점점 더 중요해지고 있는 실정이다.\n",
        "\n",
        "머신러닝을 다루는 데에 있어서 가장 기본적이고 표준이 되는 모델은 아마 선형회귀 일 것이다. 선형회귀모델을 바탕으로 머신러닝모델들의 결과를 비교해서, 블랙박스라고 불리우는 머신러닝 모델이 얼마나 효율이 좋아지는지 또, 그 예측력은 어떠한지에 대한 비교를 하기 위함인 것이다.\n",
        "\n",
        "이때 선형회귀를 함에 있어서 가장 빈번하게 나타나는 문제는 과소적합, 과대적합 이 두 가지로 일축할 수 있다. 전자는 데이터셋의 복잡성을 선형회귀로 나타내기에 학습이 충분하지 않을때 발생하는 현상이고, 후자는 모델이 훈련 데이터셋에만 치중되었기 때문에 실제 데이터셋에서 별다른 효력을 발휘하지 못하는 현상이다.\n",
        "\n",
        "또한, 모델을 학습시키는데에 있어서 데이터양이 방대해질 수록 시간이라는 비용이 점점 중요한 자원으로 작용한다. 그렇기 때문에 데이터 과적합 문제와 더불어서, 효율적인 변수만을 골라 시간을 단축시키는 기술은 필수불가결이라 할 수 있다.\n",
        "\n",
        "이에, 우리는 전진선택법, 후진소거법, 단계선택법, 라쏘/엘라스틱넷 변수선택법을 통해서 가장 기본이 되는 모델인 선형회귀모델의 효율적인 변수선택과 과적합 방지를 위한 목적으로 다음과 같은 분석을 실시하였다.\n",
        "\n",
        "준비된 데이터셋은 총 170개 정도의 피쳐들이 있는 데이터 셋이며, 과연 170개의 피쳐들중에서 각 단계마다 얼마나 효율적으로 피쳐 선택이 가능하며, 이에 따른 RMSE나 결정계수가 얼마나 증진되는지 살펴보고자 한다.\n",
        "\n",
        "선형회귀에서 과적합의 유무는 결정계수로 살펴볼 수 있고, 예측력의 변화는 RMSE로 살펴보고자 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DodoT8bMjk04"
      },
      "source": [
        "# 필요한 모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL32Nz4T9M4u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "342f7691-21c7-4934-ae5e-527a0df0d44f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp26DfBQjnxd"
      },
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "타겟 변수와 170개의 설명변수를 포함해서 총 171개의 피쳐가 있다.(모두 연속형)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "XgAmv4Er-QT7",
        "outputId": "cbcd7153-0a43-4c9c-e1f1-b05434e932b8"
      },
      "source": [
        "data=pd.read_csv('./train_data.csv')\n",
        "data=data.drop(['id'],axis=1)\n",
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target1</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.067</td>\n",
              "      <td>-1.114</td>\n",
              "      <td>-0.616</td>\n",
              "      <td>0.376</td>\n",
              "      <td>1.090</td>\n",
              "      <td>0.467</td>\n",
              "      <td>-0.422</td>\n",
              "      <td>0.460</td>\n",
              "      <td>-0.443</td>\n",
              "      <td>-0.338</td>\n",
              "      <td>0.416</td>\n",
              "      <td>-2.177</td>\n",
              "      <td>-0.326</td>\n",
              "      <td>0.340</td>\n",
              "      <td>1.174</td>\n",
              "      <td>-0.245</td>\n",
              "      <td>-1.070</td>\n",
              "      <td>-0.336</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>0.403</td>\n",
              "      <td>-0.605</td>\n",
              "      <td>-0.280</td>\n",
              "      <td>-1.618</td>\n",
              "      <td>0.878</td>\n",
              "      <td>-0.272</td>\n",
              "      <td>0.870</td>\n",
              "      <td>2.171</td>\n",
              "      <td>-0.214</td>\n",
              "      <td>0.477</td>\n",
              "      <td>-2.092</td>\n",
              "      <td>0.835</td>\n",
              "      <td>0.621</td>\n",
              "      <td>-2.810</td>\n",
              "      <td>1.029</td>\n",
              "      <td>-0.736</td>\n",
              "      <td>0.582</td>\n",
              "      <td>-0.079</td>\n",
              "      <td>0.493</td>\n",
              "      <td>1.359</td>\n",
              "      <td>-0.177</td>\n",
              "      <td>...</td>\n",
              "      <td>0.388</td>\n",
              "      <td>-1.032</td>\n",
              "      <td>-0.841</td>\n",
              "      <td>0.288</td>\n",
              "      <td>-0.230</td>\n",
              "      <td>-2.714</td>\n",
              "      <td>-0.473</td>\n",
              "      <td>0.476</td>\n",
              "      <td>-1.352</td>\n",
              "      <td>-0.922</td>\n",
              "      <td>0.329</td>\n",
              "      <td>-0.558</td>\n",
              "      <td>0.787</td>\n",
              "      <td>-1.043</td>\n",
              "      <td>-0.130</td>\n",
              "      <td>0.517</td>\n",
              "      <td>2.445</td>\n",
              "      <td>0.847</td>\n",
              "      <td>-0.636</td>\n",
              "      <td>-0.324</td>\n",
              "      <td>0.753</td>\n",
              "      <td>0.058</td>\n",
              "      <td>-1.461</td>\n",
              "      <td>-0.820</td>\n",
              "      <td>-0.076</td>\n",
              "      <td>1.127</td>\n",
              "      <td>-0.496</td>\n",
              "      <td>1.020</td>\n",
              "      <td>0.279</td>\n",
              "      <td>0.262</td>\n",
              "      <td>-0.277</td>\n",
              "      <td>-0.166</td>\n",
              "      <td>-0.089</td>\n",
              "      <td>-1.696</td>\n",
              "      <td>-0.598</td>\n",
              "      <td>-0.710</td>\n",
              "      <td>-0.431</td>\n",
              "      <td>0.355</td>\n",
              "      <td>0.966</td>\n",
              "      <td>-1.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.831</td>\n",
              "      <td>0.271</td>\n",
              "      <td>1.716</td>\n",
              "      <td>1.096</td>\n",
              "      <td>1.731</td>\n",
              "      <td>-0.197</td>\n",
              "      <td>1.904</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>0.557</td>\n",
              "      <td>1.202</td>\n",
              "      <td>0.542</td>\n",
              "      <td>0.424</td>\n",
              "      <td>-1.572</td>\n",
              "      <td>-0.968</td>\n",
              "      <td>-1.483</td>\n",
              "      <td>0.564</td>\n",
              "      <td>0.047</td>\n",
              "      <td>-0.324</td>\n",
              "      <td>-1.490</td>\n",
              "      <td>0.179</td>\n",
              "      <td>-0.524</td>\n",
              "      <td>0.250</td>\n",
              "      <td>2.462</td>\n",
              "      <td>0.029</td>\n",
              "      <td>-1.399</td>\n",
              "      <td>-2.370</td>\n",
              "      <td>-1.505</td>\n",
              "      <td>-1.294</td>\n",
              "      <td>0.106</td>\n",
              "      <td>-0.145</td>\n",
              "      <td>0.235</td>\n",
              "      <td>-1.045</td>\n",
              "      <td>1.335</td>\n",
              "      <td>1.254</td>\n",
              "      <td>-0.811</td>\n",
              "      <td>1.812</td>\n",
              "      <td>0.181</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>1.125</td>\n",
              "      <td>0.279</td>\n",
              "      <td>...</td>\n",
              "      <td>0.675</td>\n",
              "      <td>-1.015</td>\n",
              "      <td>-0.304</td>\n",
              "      <td>-1.301</td>\n",
              "      <td>-0.614</td>\n",
              "      <td>-1.176</td>\n",
              "      <td>0.117</td>\n",
              "      <td>0.075</td>\n",
              "      <td>-0.088</td>\n",
              "      <td>1.888</td>\n",
              "      <td>-0.119</td>\n",
              "      <td>0.434</td>\n",
              "      <td>0.135</td>\n",
              "      <td>1.779</td>\n",
              "      <td>0.554</td>\n",
              "      <td>-0.622</td>\n",
              "      <td>-1.214</td>\n",
              "      <td>0.389</td>\n",
              "      <td>0.136</td>\n",
              "      <td>1.035</td>\n",
              "      <td>0.101</td>\n",
              "      <td>-1.592</td>\n",
              "      <td>-0.552</td>\n",
              "      <td>1.145</td>\n",
              "      <td>0.587</td>\n",
              "      <td>1.117</td>\n",
              "      <td>-0.645</td>\n",
              "      <td>1.022</td>\n",
              "      <td>0.639</td>\n",
              "      <td>0.968</td>\n",
              "      <td>0.176</td>\n",
              "      <td>-1.132</td>\n",
              "      <td>0.119</td>\n",
              "      <td>0.428</td>\n",
              "      <td>-1.739</td>\n",
              "      <td>0.758</td>\n",
              "      <td>-1.445</td>\n",
              "      <td>0.916</td>\n",
              "      <td>-0.366</td>\n",
              "      <td>-1.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.099</td>\n",
              "      <td>1.390</td>\n",
              "      <td>-0.732</td>\n",
              "      <td>-1.065</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.081</td>\n",
              "      <td>-1.450</td>\n",
              "      <td>0.317</td>\n",
              "      <td>-0.624</td>\n",
              "      <td>-0.017</td>\n",
              "      <td>-0.665</td>\n",
              "      <td>1.905</td>\n",
              "      <td>0.376</td>\n",
              "      <td>-1.373</td>\n",
              "      <td>1.587</td>\n",
              "      <td>1.464</td>\n",
              "      <td>-1.550</td>\n",
              "      <td>-0.512</td>\n",
              "      <td>0.508</td>\n",
              "      <td>-0.094</td>\n",
              "      <td>-0.114</td>\n",
              "      <td>-0.425</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0.643</td>\n",
              "      <td>-1.371</td>\n",
              "      <td>1.553</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>-0.465</td>\n",
              "      <td>-1.252</td>\n",
              "      <td>0.443</td>\n",
              "      <td>2.205</td>\n",
              "      <td>-1.266</td>\n",
              "      <td>-0.739</td>\n",
              "      <td>0.827</td>\n",
              "      <td>-1.306</td>\n",
              "      <td>0.274</td>\n",
              "      <td>-1.573</td>\n",
              "      <td>-2.011</td>\n",
              "      <td>-1.228</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.019</td>\n",
              "      <td>0.568</td>\n",
              "      <td>0.083</td>\n",
              "      <td>-1.295</td>\n",
              "      <td>-0.312</td>\n",
              "      <td>0.252</td>\n",
              "      <td>0.325</td>\n",
              "      <td>-0.075</td>\n",
              "      <td>0.168</td>\n",
              "      <td>-0.520</td>\n",
              "      <td>0.124</td>\n",
              "      <td>0.677</td>\n",
              "      <td>1.865</td>\n",
              "      <td>-0.405</td>\n",
              "      <td>1.918</td>\n",
              "      <td>-0.847</td>\n",
              "      <td>0.819</td>\n",
              "      <td>-0.405</td>\n",
              "      <td>-0.102</td>\n",
              "      <td>1.879</td>\n",
              "      <td>-2.472</td>\n",
              "      <td>0.559</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>0.186</td>\n",
              "      <td>-1.425</td>\n",
              "      <td>-0.379</td>\n",
              "      <td>0.443</td>\n",
              "      <td>-0.887</td>\n",
              "      <td>0.868</td>\n",
              "      <td>-0.914</td>\n",
              "      <td>0.178</td>\n",
              "      <td>2.272</td>\n",
              "      <td>-0.220</td>\n",
              "      <td>0.355</td>\n",
              "      <td>1.122</td>\n",
              "      <td>1.518</td>\n",
              "      <td>-0.824</td>\n",
              "      <td>1.461</td>\n",
              "      <td>-1.124</td>\n",
              "      <td>-1.189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.989</td>\n",
              "      <td>-0.916</td>\n",
              "      <td>-1.343</td>\n",
              "      <td>0.145</td>\n",
              "      <td>0.543</td>\n",
              "      <td>0.636</td>\n",
              "      <td>1.127</td>\n",
              "      <td>0.189</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>-0.638</td>\n",
              "      <td>0.760</td>\n",
              "      <td>-0.360</td>\n",
              "      <td>-2.048</td>\n",
              "      <td>-0.996</td>\n",
              "      <td>-0.361</td>\n",
              "      <td>0.962</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.595</td>\n",
              "      <td>-0.943</td>\n",
              "      <td>0.069</td>\n",
              "      <td>0.483</td>\n",
              "      <td>-0.063</td>\n",
              "      <td>-0.540</td>\n",
              "      <td>-0.551</td>\n",
              "      <td>-1.736</td>\n",
              "      <td>-2.014</td>\n",
              "      <td>0.636</td>\n",
              "      <td>-1.147</td>\n",
              "      <td>-0.767</td>\n",
              "      <td>-0.678</td>\n",
              "      <td>0.815</td>\n",
              "      <td>1.696</td>\n",
              "      <td>-0.436</td>\n",
              "      <td>-1.777</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.318</td>\n",
              "      <td>0.978</td>\n",
              "      <td>1.299</td>\n",
              "      <td>-0.540</td>\n",
              "      <td>0.248</td>\n",
              "      <td>...</td>\n",
              "      <td>0.401</td>\n",
              "      <td>-0.287</td>\n",
              "      <td>0.552</td>\n",
              "      <td>-0.112</td>\n",
              "      <td>1.261</td>\n",
              "      <td>0.323</td>\n",
              "      <td>0.511</td>\n",
              "      <td>-0.221</td>\n",
              "      <td>-0.593</td>\n",
              "      <td>1.117</td>\n",
              "      <td>-2.027</td>\n",
              "      <td>-0.108</td>\n",
              "      <td>-1.131</td>\n",
              "      <td>-0.871</td>\n",
              "      <td>1.177</td>\n",
              "      <td>-0.065</td>\n",
              "      <td>1.142</td>\n",
              "      <td>0.280</td>\n",
              "      <td>-0.806</td>\n",
              "      <td>-1.176</td>\n",
              "      <td>0.908</td>\n",
              "      <td>1.831</td>\n",
              "      <td>0.151</td>\n",
              "      <td>-1.386</td>\n",
              "      <td>-0.752</td>\n",
              "      <td>1.923</td>\n",
              "      <td>-1.216</td>\n",
              "      <td>0.995</td>\n",
              "      <td>-0.162</td>\n",
              "      <td>1.560</td>\n",
              "      <td>-0.787</td>\n",
              "      <td>-1.460</td>\n",
              "      <td>1.170</td>\n",
              "      <td>-1.188</td>\n",
              "      <td>2.634</td>\n",
              "      <td>1.044</td>\n",
              "      <td>-0.699</td>\n",
              "      <td>1.283</td>\n",
              "      <td>0.366</td>\n",
              "      <td>1.188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.811</td>\n",
              "      <td>-1.509</td>\n",
              "      <td>0.522</td>\n",
              "      <td>-0.360</td>\n",
              "      <td>-0.220</td>\n",
              "      <td>-0.959</td>\n",
              "      <td>0.334</td>\n",
              "      <td>-0.566</td>\n",
              "      <td>-0.656</td>\n",
              "      <td>-0.499</td>\n",
              "      <td>-0.653</td>\n",
              "      <td>-0.058</td>\n",
              "      <td>-0.046</td>\n",
              "      <td>0.654</td>\n",
              "      <td>-0.697</td>\n",
              "      <td>-1.175</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.484</td>\n",
              "      <td>0.402</td>\n",
              "      <td>-1.037</td>\n",
              "      <td>1.081</td>\n",
              "      <td>0.716</td>\n",
              "      <td>-0.144</td>\n",
              "      <td>1.720</td>\n",
              "      <td>-1.980</td>\n",
              "      <td>-0.741</td>\n",
              "      <td>-1.493</td>\n",
              "      <td>-0.860</td>\n",
              "      <td>-0.082</td>\n",
              "      <td>0.133</td>\n",
              "      <td>1.084</td>\n",
              "      <td>-0.719</td>\n",
              "      <td>0.198</td>\n",
              "      <td>1.144</td>\n",
              "      <td>1.123</td>\n",
              "      <td>0.435</td>\n",
              "      <td>-0.296</td>\n",
              "      <td>-2.933</td>\n",
              "      <td>0.831</td>\n",
              "      <td>1.905</td>\n",
              "      <td>...</td>\n",
              "      <td>2.564</td>\n",
              "      <td>-0.646</td>\n",
              "      <td>0.209</td>\n",
              "      <td>-1.968</td>\n",
              "      <td>0.462</td>\n",
              "      <td>2.042</td>\n",
              "      <td>-1.328</td>\n",
              "      <td>0.991</td>\n",
              "      <td>-0.167</td>\n",
              "      <td>-0.066</td>\n",
              "      <td>-0.866</td>\n",
              "      <td>-0.582</td>\n",
              "      <td>-1.644</td>\n",
              "      <td>-0.380</td>\n",
              "      <td>0.703</td>\n",
              "      <td>-0.869</td>\n",
              "      <td>-0.617</td>\n",
              "      <td>0.987</td>\n",
              "      <td>0.990</td>\n",
              "      <td>-0.980</td>\n",
              "      <td>0.110</td>\n",
              "      <td>-1.486</td>\n",
              "      <td>-1.458</td>\n",
              "      <td>-1.369</td>\n",
              "      <td>-0.349</td>\n",
              "      <td>1.564</td>\n",
              "      <td>-0.385</td>\n",
              "      <td>-1.240</td>\n",
              "      <td>-1.144</td>\n",
              "      <td>-1.880</td>\n",
              "      <td>-0.408</td>\n",
              "      <td>-0.422</td>\n",
              "      <td>-1.588</td>\n",
              "      <td>0.517</td>\n",
              "      <td>-0.381</td>\n",
              "      <td>-1.308</td>\n",
              "      <td>-1.014</td>\n",
              "      <td>-0.999</td>\n",
              "      <td>0.519</td>\n",
              "      <td>1.545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>-0.068</td>\n",
              "      <td>-0.184</td>\n",
              "      <td>-1.153</td>\n",
              "      <td>0.610</td>\n",
              "      <td>0.414</td>\n",
              "      <td>1.557</td>\n",
              "      <td>-0.234</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.896</td>\n",
              "      <td>1.416</td>\n",
              "      <td>0.149</td>\n",
              "      <td>-0.194</td>\n",
              "      <td>0.552</td>\n",
              "      <td>-0.073</td>\n",
              "      <td>-1.353</td>\n",
              "      <td>-1.485</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.110</td>\n",
              "      <td>-0.367</td>\n",
              "      <td>-1.833</td>\n",
              "      <td>0.414</td>\n",
              "      <td>0.664</td>\n",
              "      <td>0.956</td>\n",
              "      <td>-1.941</td>\n",
              "      <td>-0.868</td>\n",
              "      <td>0.522</td>\n",
              "      <td>-1.463</td>\n",
              "      <td>-1.148</td>\n",
              "      <td>0.107</td>\n",
              "      <td>-1.592</td>\n",
              "      <td>-0.944</td>\n",
              "      <td>-0.238</td>\n",
              "      <td>-1.372</td>\n",
              "      <td>-3.606</td>\n",
              "      <td>1.378</td>\n",
              "      <td>-1.453</td>\n",
              "      <td>-0.286</td>\n",
              "      <td>0.322</td>\n",
              "      <td>-0.638</td>\n",
              "      <td>1.612</td>\n",
              "      <td>...</td>\n",
              "      <td>1.048</td>\n",
              "      <td>2.560</td>\n",
              "      <td>-0.584</td>\n",
              "      <td>0.562</td>\n",
              "      <td>0.036</td>\n",
              "      <td>-1.062</td>\n",
              "      <td>-0.520</td>\n",
              "      <td>-1.371</td>\n",
              "      <td>0.086</td>\n",
              "      <td>1.292</td>\n",
              "      <td>-0.022</td>\n",
              "      <td>0.711</td>\n",
              "      <td>-0.742</td>\n",
              "      <td>-0.576</td>\n",
              "      <td>0.093</td>\n",
              "      <td>1.029</td>\n",
              "      <td>0.401</td>\n",
              "      <td>1.042</td>\n",
              "      <td>-0.976</td>\n",
              "      <td>0.927</td>\n",
              "      <td>1.751</td>\n",
              "      <td>-0.802</td>\n",
              "      <td>1.271</td>\n",
              "      <td>-1.085</td>\n",
              "      <td>-0.446</td>\n",
              "      <td>-0.680</td>\n",
              "      <td>0.350</td>\n",
              "      <td>-0.747</td>\n",
              "      <td>1.288</td>\n",
              "      <td>-0.016</td>\n",
              "      <td>-0.237</td>\n",
              "      <td>0.338</td>\n",
              "      <td>-0.571</td>\n",
              "      <td>-0.405</td>\n",
              "      <td>0.674</td>\n",
              "      <td>0.765</td>\n",
              "      <td>-1.129</td>\n",
              "      <td>0.866</td>\n",
              "      <td>-0.986</td>\n",
              "      <td>-0.171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>-0.234</td>\n",
              "      <td>-1.373</td>\n",
              "      <td>-2.050</td>\n",
              "      <td>-0.408</td>\n",
              "      <td>-0.255</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.986</td>\n",
              "      <td>-0.891</td>\n",
              "      <td>-0.268</td>\n",
              "      <td>-0.569</td>\n",
              "      <td>0.725</td>\n",
              "      <td>-0.262</td>\n",
              "      <td>0.647</td>\n",
              "      <td>-0.529</td>\n",
              "      <td>1.145</td>\n",
              "      <td>-0.279</td>\n",
              "      <td>-0.955</td>\n",
              "      <td>-1.184</td>\n",
              "      <td>-0.598</td>\n",
              "      <td>-0.865</td>\n",
              "      <td>0.237</td>\n",
              "      <td>0.732</td>\n",
              "      <td>-0.925</td>\n",
              "      <td>1.473</td>\n",
              "      <td>0.573</td>\n",
              "      <td>-0.796</td>\n",
              "      <td>-0.558</td>\n",
              "      <td>-0.862</td>\n",
              "      <td>1.235</td>\n",
              "      <td>-0.965</td>\n",
              "      <td>-0.391</td>\n",
              "      <td>0.525</td>\n",
              "      <td>-1.531</td>\n",
              "      <td>-0.527</td>\n",
              "      <td>1.711</td>\n",
              "      <td>-0.056</td>\n",
              "      <td>0.395</td>\n",
              "      <td>0.560</td>\n",
              "      <td>-2.289</td>\n",
              "      <td>0.915</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.569</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>1.378</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>-0.310</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.018</td>\n",
              "      <td>0.066</td>\n",
              "      <td>0.189</td>\n",
              "      <td>1.601</td>\n",
              "      <td>-0.895</td>\n",
              "      <td>1.184</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.100</td>\n",
              "      <td>1.439</td>\n",
              "      <td>0.697</td>\n",
              "      <td>0.705</td>\n",
              "      <td>-0.268</td>\n",
              "      <td>-1.360</td>\n",
              "      <td>0.336</td>\n",
              "      <td>0.170</td>\n",
              "      <td>-0.259</td>\n",
              "      <td>1.077</td>\n",
              "      <td>-0.886</td>\n",
              "      <td>1.900</td>\n",
              "      <td>0.651</td>\n",
              "      <td>-0.455</td>\n",
              "      <td>-0.193</td>\n",
              "      <td>1.355</td>\n",
              "      <td>0.222</td>\n",
              "      <td>0.763</td>\n",
              "      <td>-0.481</td>\n",
              "      <td>1.664</td>\n",
              "      <td>-1.021</td>\n",
              "      <td>-0.458</td>\n",
              "      <td>1.542</td>\n",
              "      <td>-0.156</td>\n",
              "      <td>-2.429</td>\n",
              "      <td>2.242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>-2.327</td>\n",
              "      <td>-1.834</td>\n",
              "      <td>-0.762</td>\n",
              "      <td>0.660</td>\n",
              "      <td>-0.858</td>\n",
              "      <td>-2.764</td>\n",
              "      <td>-0.539</td>\n",
              "      <td>-0.065</td>\n",
              "      <td>0.549</td>\n",
              "      <td>1.474</td>\n",
              "      <td>0.565</td>\n",
              "      <td>-1.128</td>\n",
              "      <td>1.600</td>\n",
              "      <td>-0.291</td>\n",
              "      <td>0.484</td>\n",
              "      <td>1.559</td>\n",
              "      <td>-0.690</td>\n",
              "      <td>0.267</td>\n",
              "      <td>-0.502</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.504</td>\n",
              "      <td>1.799</td>\n",
              "      <td>0.852</td>\n",
              "      <td>1.018</td>\n",
              "      <td>-0.193</td>\n",
              "      <td>-0.981</td>\n",
              "      <td>0.142</td>\n",
              "      <td>1.037</td>\n",
              "      <td>-0.124</td>\n",
              "      <td>-0.219</td>\n",
              "      <td>-0.739</td>\n",
              "      <td>-0.238</td>\n",
              "      <td>-0.561</td>\n",
              "      <td>-0.790</td>\n",
              "      <td>-1.842</td>\n",
              "      <td>0.274</td>\n",
              "      <td>-0.066</td>\n",
              "      <td>0.399</td>\n",
              "      <td>-0.393</td>\n",
              "      <td>-0.042</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.194</td>\n",
              "      <td>1.036</td>\n",
              "      <td>-0.347</td>\n",
              "      <td>1.723</td>\n",
              "      <td>-0.825</td>\n",
              "      <td>0.248</td>\n",
              "      <td>1.416</td>\n",
              "      <td>0.342</td>\n",
              "      <td>0.348</td>\n",
              "      <td>0.843</td>\n",
              "      <td>-1.240</td>\n",
              "      <td>-1.439</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.057</td>\n",
              "      <td>-0.419</td>\n",
              "      <td>-0.323</td>\n",
              "      <td>-0.428</td>\n",
              "      <td>-0.534</td>\n",
              "      <td>1.105</td>\n",
              "      <td>-1.033</td>\n",
              "      <td>-0.353</td>\n",
              "      <td>-0.093</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.679</td>\n",
              "      <td>0.867</td>\n",
              "      <td>-0.432</td>\n",
              "      <td>-2.635</td>\n",
              "      <td>1.022</td>\n",
              "      <td>-0.083</td>\n",
              "      <td>1.007</td>\n",
              "      <td>-0.856</td>\n",
              "      <td>-0.763</td>\n",
              "      <td>-0.691</td>\n",
              "      <td>-0.395</td>\n",
              "      <td>-0.645</td>\n",
              "      <td>-1.421</td>\n",
              "      <td>-1.610</td>\n",
              "      <td>-1.221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>-0.451</td>\n",
              "      <td>-0.204</td>\n",
              "      <td>-0.762</td>\n",
              "      <td>0.261</td>\n",
              "      <td>0.022</td>\n",
              "      <td>-1.487</td>\n",
              "      <td>-1.122</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.369</td>\n",
              "      <td>-0.173</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.039</td>\n",
              "      <td>-0.903</td>\n",
              "      <td>0.353</td>\n",
              "      <td>0.807</td>\n",
              "      <td>-1.658</td>\n",
              "      <td>-0.855</td>\n",
              "      <td>-1.728</td>\n",
              "      <td>-0.446</td>\n",
              "      <td>-0.807</td>\n",
              "      <td>-0.610</td>\n",
              "      <td>0.949</td>\n",
              "      <td>1.936</td>\n",
              "      <td>1.927</td>\n",
              "      <td>-0.398</td>\n",
              "      <td>1.129</td>\n",
              "      <td>-0.462</td>\n",
              "      <td>0.291</td>\n",
              "      <td>0.924</td>\n",
              "      <td>-1.739</td>\n",
              "      <td>1.103</td>\n",
              "      <td>0.736</td>\n",
              "      <td>-1.145</td>\n",
              "      <td>1.036</td>\n",
              "      <td>0.195</td>\n",
              "      <td>0.879</td>\n",
              "      <td>0.171</td>\n",
              "      <td>-1.144</td>\n",
              "      <td>-0.481</td>\n",
              "      <td>-1.654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500</td>\n",
              "      <td>-1.059</td>\n",
              "      <td>-0.257</td>\n",
              "      <td>-0.647</td>\n",
              "      <td>-0.620</td>\n",
              "      <td>-0.768</td>\n",
              "      <td>1.834</td>\n",
              "      <td>0.547</td>\n",
              "      <td>1.245</td>\n",
              "      <td>0.279</td>\n",
              "      <td>-0.578</td>\n",
              "      <td>-0.267</td>\n",
              "      <td>0.010</td>\n",
              "      <td>-1.684</td>\n",
              "      <td>-1.683</td>\n",
              "      <td>-0.631</td>\n",
              "      <td>-0.073</td>\n",
              "      <td>-0.334</td>\n",
              "      <td>-0.986</td>\n",
              "      <td>0.536</td>\n",
              "      <td>-0.023</td>\n",
              "      <td>-1.211</td>\n",
              "      <td>-2.728</td>\n",
              "      <td>0.670</td>\n",
              "      <td>0.456</td>\n",
              "      <td>-0.220</td>\n",
              "      <td>-0.411</td>\n",
              "      <td>-0.246</td>\n",
              "      <td>2.148</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>-0.692</td>\n",
              "      <td>-0.215</td>\n",
              "      <td>0.263</td>\n",
              "      <td>0.368</td>\n",
              "      <td>-1.818</td>\n",
              "      <td>-0.142</td>\n",
              "      <td>-0.701</td>\n",
              "      <td>-0.373</td>\n",
              "      <td>-0.953</td>\n",
              "      <td>-1.435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>0.725</td>\n",
              "      <td>1.064</td>\n",
              "      <td>1.333</td>\n",
              "      <td>-2.863</td>\n",
              "      <td>0.203</td>\n",
              "      <td>1.898</td>\n",
              "      <td>0.434</td>\n",
              "      <td>1.207</td>\n",
              "      <td>-0.015</td>\n",
              "      <td>1.459</td>\n",
              "      <td>-0.667</td>\n",
              "      <td>0.880</td>\n",
              "      <td>-0.377</td>\n",
              "      <td>-0.914</td>\n",
              "      <td>1.109</td>\n",
              "      <td>-1.569</td>\n",
              "      <td>-0.447</td>\n",
              "      <td>-1.159</td>\n",
              "      <td>0.674</td>\n",
              "      <td>0.515</td>\n",
              "      <td>1.298</td>\n",
              "      <td>0.797</td>\n",
              "      <td>0.611</td>\n",
              "      <td>-0.401</td>\n",
              "      <td>0.450</td>\n",
              "      <td>1.295</td>\n",
              "      <td>1.349</td>\n",
              "      <td>0.719</td>\n",
              "      <td>-0.834</td>\n",
              "      <td>0.106</td>\n",
              "      <td>-0.053</td>\n",
              "      <td>-0.030</td>\n",
              "      <td>-0.202</td>\n",
              "      <td>0.545</td>\n",
              "      <td>-0.914</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.345</td>\n",
              "      <td>1.655</td>\n",
              "      <td>-1.875</td>\n",
              "      <td>-1.948</td>\n",
              "      <td>...</td>\n",
              "      <td>0.429</td>\n",
              "      <td>0.290</td>\n",
              "      <td>-0.903</td>\n",
              "      <td>0.619</td>\n",
              "      <td>0.641</td>\n",
              "      <td>-0.254</td>\n",
              "      <td>-0.133</td>\n",
              "      <td>0.418</td>\n",
              "      <td>1.154</td>\n",
              "      <td>0.130</td>\n",
              "      <td>-0.451</td>\n",
              "      <td>-0.765</td>\n",
              "      <td>-1.651</td>\n",
              "      <td>-0.022</td>\n",
              "      <td>1.412</td>\n",
              "      <td>0.770</td>\n",
              "      <td>0.690</td>\n",
              "      <td>1.079</td>\n",
              "      <td>1.008</td>\n",
              "      <td>1.071</td>\n",
              "      <td>-0.730</td>\n",
              "      <td>1.682</td>\n",
              "      <td>-1.294</td>\n",
              "      <td>0.347</td>\n",
              "      <td>0.101</td>\n",
              "      <td>-0.349</td>\n",
              "      <td>-0.287</td>\n",
              "      <td>-1.035</td>\n",
              "      <td>-0.745</td>\n",
              "      <td>1.647</td>\n",
              "      <td>0.366</td>\n",
              "      <td>1.185</td>\n",
              "      <td>1.384</td>\n",
              "      <td>-1.109</td>\n",
              "      <td>1.051</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.026</td>\n",
              "      <td>-0.064</td>\n",
              "      <td>-0.217</td>\n",
              "      <td>-0.220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250 rows × 171 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     target1      1      2      3      4  ...    166    167    168    169    170\n",
              "0     -1.067 -1.114 -0.616  0.376  1.090  ... -0.710 -0.431  0.355  0.966 -1.134\n",
              "1     -0.831  0.271  1.716  1.096  1.731  ...  0.758 -1.445  0.916 -0.366 -1.132\n",
              "2      0.099  1.390 -0.732 -1.065  0.005  ...  1.518 -0.824  1.461 -1.124 -1.189\n",
              "3     -0.989 -0.916 -1.343  0.145  0.543  ...  1.044 -0.699  1.283  0.366  1.188\n",
              "4      0.811 -1.509  0.522 -0.360 -0.220  ... -1.308 -1.014 -0.999  0.519  1.545\n",
              "..       ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
              "245   -0.068 -0.184 -1.153  0.610  0.414  ...  0.765 -1.129  0.866 -0.986 -0.171\n",
              "246   -0.234 -1.373 -2.050 -0.408 -0.255  ... -0.458  1.542 -0.156 -2.429  2.242\n",
              "247   -2.327 -1.834 -0.762  0.660 -0.858  ... -0.395 -0.645 -1.421 -1.610 -1.221\n",
              "248   -0.451 -0.204 -0.762  0.261  0.022  ... -0.142 -0.701 -0.373 -0.953 -1.435\n",
              "249    0.725  1.064  1.333 -2.863  0.203  ...  0.614  0.026 -0.064 -0.217 -0.220\n",
              "\n",
              "[250 rows x 171 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyfS2HNBnrMg"
      },
      "source": [
        "# 결측값 조사\n",
        "결측값은 없다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wbWonBmsbUJA",
        "outputId": "cd07affb-b4fc-46e3-d421-f2385ed862e1"
      },
      "source": [
        "data.isnull().sum().sum()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B07tHqwfntxX"
      },
      "source": [
        "# 훈련, 테스트 데이터셋으로 분할하는 과정\n",
        "테스트 데이터 사이즈는 30%로 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prxuTcOfPvnx"
      },
      "source": [
        "x_train, x_test, y_train, y_test= train_test_split(data.drop(['target1'],axis=1),data['target1'], test_size=0.3, random_state=35)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4x6mmOqnzJl"
      },
      "source": [
        "# 훈련, 테스트 데이터셋 완성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dZZgcfuQziZ"
      },
      "source": [
        "train_set=pd.concat([y_train,x_train],axis=1)\n",
        "test_set=pd.concat([y_test,x_test],axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2YDCHVhn2f0"
      },
      "source": [
        "# Initial variance를 선택하기 위해서 상관계수를 살펴본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "5IO13kWR-S1N",
        "outputId": "3db858e2-0b11-4dc3-afe2-44fa65df4266"
      },
      "source": [
        "data_corr=pd.DataFrame(train_set.corr().iloc[0])\n",
        "data_corr=data_corr.drop(['target1'],axis=0)\n",
        "data_corr=abs(data_corr)\n",
        "data_corr"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.020032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.096899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.137090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.066852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.103326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>0.106478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>0.046483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>0.085026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>0.042001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>0.071132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>170 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      target1\n",
              "1    0.020032\n",
              "2    0.096899\n",
              "3    0.137090\n",
              "4    0.066852\n",
              "5    0.103326\n",
              "..        ...\n",
              "166  0.106478\n",
              "167  0.046483\n",
              "168  0.085026\n",
              "169  0.042001\n",
              "170  0.071132\n",
              "\n",
              "[170 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3XLGygOn8B0"
      },
      "source": [
        "# 가장 높은 상관계수는 무엇일까?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "uCPr2N_B-YGq",
        "outputId": "146fdce1-c3fc-4a71-fd6c-3e842765e54d"
      },
      "source": [
        "data_corr[data_corr['target1'] == data_corr['target1'].max()]"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>0.235115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     target1\n",
              "86  0.235115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjigatEboAaV"
      },
      "source": [
        "# 실제로 그런지 확인해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2tklSkTQ_F13",
        "outputId": "67ee312f-7b34-4bd1-fadf-cfb3c4fa310e"
      },
      "source": [
        "# 실제로 그런지 확인해보기\n",
        "print(data_corr.loc['86'])\n",
        "print(data_corr.max())"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target1    0.235115\n",
            "Name: 86, dtype: float64\n",
            "target1    0.235115\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf3iIKM0oEDq"
      },
      "source": [
        "# 전진 선택법\n",
        "\n",
        "초기 변수로 상관계수가 가장 높게 나온 변수를 선택한다.\n",
        "그 이후에 하나씩 변수를 넣어주면서 검정통계량을 통해 기각 유무를 결정한다.\n",
        "그리고 그것을 통해 선택된 변수가 들어오게 되면, 결정계수와 테스트 데이터셋을 통한 RMSE를 살펴보고 어떤 변화가 있는지 살펴본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AgCRrGxk_17P",
        "outputId": "6e908942-28d5-4121-fa15-72cb79ce5265"
      },
      "source": [
        "# 전진선택법\n",
        "data2=train_set.copy()\n",
        "data_forward=test_set.copy()\n",
        "data_corr2=abs(data_corr)\n",
        "forward=pd.DataFrame()\n",
        "forward1=pd.DataFrame()\n",
        "for num in range(1,int(len(data2.T))):\n",
        "  if num == 1 :\n",
        "    data_corr2=pd.DataFrame(data2.corr().iloc[0])\n",
        "    data_corr2=data_corr2.drop(['target1'],axis=0)\n",
        "    cor=data_corr2[data_corr2['target1'] == data_corr2['target1'].max()].index[0]\n",
        "    variable=pd.DataFrame(data2[cor])\n",
        "    variable1=pd.DataFrame(data_forward[cor])\n",
        "    model=sm.OLS(data2['target1'],variable).fit()\n",
        "    if model.pvalues.values[-1] >= 0.05:\n",
        "      data2=data2.drop([cor],axis=1)\n",
        "    else:\n",
        "      forward_predict = model.predict(variable1)\n",
        "      forward_r2=model.rsquared\n",
        "      forward_rmse=np.sqrt(np.mean((test_set['target1'] - forward_predict) ** 2 ))\n",
        "      print('초기변수의 결정계수 :', forward_r2)\n",
        "      print('초기변수의 RMSE :', forward_rmse)\n",
        "      print()\n",
        "      forward=pd.concat([forward,variable], axis=1)\n",
        "      forward1=pd.concat([forward1,variable1], axis=1)\n",
        "      data2=data2.drop([cor],axis=1)\n",
        "  else:\n",
        "    data_corr2=abs(pd.DataFrame(data2.corr().iloc[0]))\n",
        "    data_corr2=data_corr2.drop(['target1'],axis=0)\n",
        "    cor=data_corr2[data_corr2['target1'] == data_corr2['target1'].max()].index[0]\n",
        "    variable=pd.DataFrame(data2[cor])\n",
        "    variable1=pd.DataFrame(data_forward[cor])\n",
        "    forward=pd.concat([forward,variable],axis=1)\n",
        "    forward1=pd.concat([forward1,variable1], axis=1)\n",
        "    model=sm.OLS(data2['target1'],forward).fit()\n",
        "    \n",
        "\n",
        "    if model.pvalues.values[-1] >= 0.05:\n",
        "      forward=forward.drop([cor],axis=1)\n",
        "      forward1=forward1.drop([cor],axis=1)\n",
        "      data2=data2.drop([cor],axis=1)\n",
        "      \n",
        "    else:\n",
        "      forward_predict = model.predict(forward1)\n",
        "      forward_r2=model.rsquared\n",
        "      forward_rmse=np.sqrt(np.mean((test_set['target1'] - forward_predict) ** 2 ))\n",
        "      print('변수선택후의 결정계수 :', forward_r2)\n",
        "      print('변수선택후의 RMSE :', forward_rmse)\n",
        "      print()\n",
        "      data2=data2.drop([cor],axis=1) \n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "초기변수의 결정계수 : 0.05548951523342183\n",
            "초기변수의 RMSE : 1.0447493699766581\n",
            "\n",
            "변수선택후의 결정계수 : 0.10974808579502837\n",
            "변수선택후의 RMSE : 1.0485303748792427\n",
            "\n",
            "변수선택후의 결정계수 : 0.1406939103699859\n",
            "변수선택후의 RMSE : 1.1021573000985192\n",
            "\n",
            "변수선택후의 결정계수 : 0.16618283384030608\n",
            "변수선택후의 RMSE : 1.1169615722572583\n",
            "\n",
            "변수선택후의 결정계수 : 0.19264620691747092\n",
            "변수선택후의 RMSE : 1.1178872936915505\n",
            "\n",
            "변수선택후의 결정계수 : 0.2167786100997957\n",
            "변수선택후의 RMSE : 1.0998983235591446\n",
            "\n",
            "변수선택후의 결정계수 : 0.2366888731414628\n",
            "변수선택후의 RMSE : 1.1022037641027569\n",
            "\n",
            "변수선택후의 결정계수 : 0.26392619961217867\n",
            "변수선택후의 RMSE : 1.1011260411640147\n",
            "\n",
            "변수선택후의 결정계수 : 0.28717851241356884\n",
            "변수선택후의 RMSE : 1.1607156676195367\n",
            "\n",
            "변수선택후의 결정계수 : 0.32162906126708746\n",
            "변수선택후의 RMSE : 1.228283449000363\n",
            "\n",
            "변수선택후의 결정계수 : 0.33970618735400204\n",
            "변수선택후의 RMSE : 1.2453021837398446\n",
            "\n",
            "변수선택후의 결정계수 : 0.35786704183722295\n",
            "변수선택후의 RMSE : 1.2628664003411232\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jRPjnm2oSTp"
      },
      "source": [
        "# 결국 다음과 같은 변수들이 선택되었다.\n",
        "\n",
        "최종적으로 결정계수는 035786, RMSE는 1.2628이 나왔다.\n",
        "결정계수로 보자면 과적합 문제는 충분히 피한듯 보인다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "pCa0BCGmZL-A",
        "outputId": "e5f1c3f0-9f9c-4f15-c6d5-4a39f8435ab5"
      },
      "source": [
        "forward"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>86</th>\n",
              "      <th>30</th>\n",
              "      <th>164</th>\n",
              "      <th>17</th>\n",
              "      <th>20</th>\n",
              "      <th>48</th>\n",
              "      <th>29</th>\n",
              "      <th>134</th>\n",
              "      <th>64</th>\n",
              "      <th>7</th>\n",
              "      <th>141</th>\n",
              "      <th>138</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.507</td>\n",
              "      <td>2.389</td>\n",
              "      <td>0.127</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>0.269</td>\n",
              "      <td>-0.968</td>\n",
              "      <td>0.187</td>\n",
              "      <td>0.028</td>\n",
              "      <td>-0.364</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-1.112</td>\n",
              "      <td>0.127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>-1.451</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>1.012</td>\n",
              "      <td>0.436</td>\n",
              "      <td>-0.731</td>\n",
              "      <td>0.098</td>\n",
              "      <td>0.934</td>\n",
              "      <td>-0.425</td>\n",
              "      <td>0.434</td>\n",
              "      <td>-0.734</td>\n",
              "      <td>0.542</td>\n",
              "      <td>0.329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.559</td>\n",
              "      <td>0.725</td>\n",
              "      <td>-1.245</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.456</td>\n",
              "      <td>-1.473</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.121</td>\n",
              "      <td>-1.192</td>\n",
              "      <td>0.217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>0.833</td>\n",
              "      <td>-2.081</td>\n",
              "      <td>-0.735</td>\n",
              "      <td>0.077</td>\n",
              "      <td>-0.810</td>\n",
              "      <td>0.078</td>\n",
              "      <td>-0.574</td>\n",
              "      <td>0.535</td>\n",
              "      <td>-1.701</td>\n",
              "      <td>0.173</td>\n",
              "      <td>0.615</td>\n",
              "      <td>0.821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>-0.357</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.223</td>\n",
              "      <td>-0.488</td>\n",
              "      <td>-0.336</td>\n",
              "      <td>0.339</td>\n",
              "      <td>-0.061</td>\n",
              "      <td>0.973</td>\n",
              "      <td>0.171</td>\n",
              "      <td>-1.800</td>\n",
              "      <td>0.657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1.088</td>\n",
              "      <td>-1.187</td>\n",
              "      <td>-2.229</td>\n",
              "      <td>0.412</td>\n",
              "      <td>-1.165</td>\n",
              "      <td>1.910</td>\n",
              "      <td>-0.055</td>\n",
              "      <td>0.180</td>\n",
              "      <td>-0.440</td>\n",
              "      <td>1.022</td>\n",
              "      <td>1.512</td>\n",
              "      <td>-0.293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>0.144</td>\n",
              "      <td>-1.801</td>\n",
              "      <td>-1.236</td>\n",
              "      <td>-1.796</td>\n",
              "      <td>-1.733</td>\n",
              "      <td>0.897</td>\n",
              "      <td>-1.340</td>\n",
              "      <td>3.032</td>\n",
              "      <td>-1.079</td>\n",
              "      <td>0.921</td>\n",
              "      <td>-0.899</td>\n",
              "      <td>0.720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>-1.677</td>\n",
              "      <td>-0.652</td>\n",
              "      <td>-1.126</td>\n",
              "      <td>-0.469</td>\n",
              "      <td>-0.367</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.606</td>\n",
              "      <td>0.566</td>\n",
              "      <td>-1.603</td>\n",
              "      <td>-0.370</td>\n",
              "      <td>0.011</td>\n",
              "      <td>-0.041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-1.622</td>\n",
              "      <td>-0.760</td>\n",
              "      <td>-1.007</td>\n",
              "      <td>0.262</td>\n",
              "      <td>0.109</td>\n",
              "      <td>-0.578</td>\n",
              "      <td>0.093</td>\n",
              "      <td>1.159</td>\n",
              "      <td>-0.621</td>\n",
              "      <td>0.661</td>\n",
              "      <td>0.696</td>\n",
              "      <td>1.224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>1.738</td>\n",
              "      <td>-1.468</td>\n",
              "      <td>-1.158</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.518</td>\n",
              "      <td>-0.677</td>\n",
              "      <td>-0.649</td>\n",
              "      <td>0.835</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>-0.098</td>\n",
              "      <td>0.174</td>\n",
              "      <td>0.309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        86     30    164     17     20  ...    134     64      7    141    138\n",
              "36   0.507  2.389  0.127 -0.048  0.269  ...  0.028 -0.364  0.005 -1.112  0.127\n",
              "46  -1.451 -0.118  1.012  0.436 -0.731  ... -0.425  0.434 -0.734  0.542  0.329\n",
              "97   0.559  0.725 -1.245 -0.918  0.003  ... -0.374  0.184  0.121 -1.192  0.217\n",
              "143  0.833 -2.081 -0.735  0.077 -0.810  ...  0.535 -1.701  0.173  0.615  0.821\n",
              "112 -0.357  0.920  0.731  0.223 -0.488  ... -0.061  0.973  0.171 -1.800  0.657\n",
              "..     ...    ...    ...    ...    ...  ...    ...    ...    ...    ...    ...\n",
              "33   1.088 -1.187 -2.229  0.412 -1.165  ...  0.180 -0.440  1.022  1.512 -0.293\n",
              "183  0.144 -1.801 -1.236 -1.796 -1.733  ...  3.032 -1.079  0.921 -0.899  0.720\n",
              "236 -1.677 -0.652 -1.126 -0.469 -0.367  ...  0.566 -1.603 -0.370  0.011 -0.041\n",
              "15  -1.622 -0.760 -1.007  0.262  0.109  ...  1.159 -0.621  0.661  0.696  1.224\n",
              "201  1.738 -1.468 -1.158  0.003  0.518  ...  0.835 -0.062 -0.098  0.174  0.309\n",
              "\n",
              "[175 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo8BMhbXovrp"
      },
      "source": [
        "# 후진소거법\n",
        "\n",
        "초기에 모든 변수를 선형회귀 모델에 적합시킨다.\n",
        "그리고 나서, 가장 유의하지 않은(insignificant) 변수를 하나씩 골라 제거한다.\n",
        "그리고 남은 변수들의 검정통계량을 통해 유의성을 살피고, 유의한 변수들이 남을때 까지 이를 반복한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X-vjlLaSHIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "959204ea-155e-461c-cadf-e3bc51a1441f"
      },
      "source": [
        "# 후진선택법\n",
        "data2=train_set.copy()\n",
        "data_backward=test_set.copy()\n",
        "data_corr2=abs(data_corr)\n",
        "for num in range(1,int(len(data2.T))):\n",
        "  if num == 1 :\n",
        "    model2=sm.OLS(data2['target1'],data2.drop(['target1'],axis=1)).fit()\n",
        "    backward_predict = model2.predict(data_backward.drop(['target1'],axis=1))\n",
        "    backward_r2=model2.rsquared\n",
        "    backward_rmse=np.sqrt(np.mean((test_set['target1'] - backward_predict) ** 2 ))\n",
        "    print('초기의 결정계수 :', backward_r2)\n",
        "    print('초기의 RMSE :', backward_rmse)\n",
        "    print()\n",
        "  else:\n",
        "    model2=sm.OLS(data2['target1'],data2.drop(['target1'],axis=1)).fit()\n",
        "    if model2.pvalues.max() >= 0.05:\n",
        "      cor=model2.pvalues[model2.pvalues == model2.pvalues.max()].index[0]\n",
        "      data2=data2.drop([cor],axis=1)\n",
        "      data_backward=data_backward.drop([cor],axis=1)\n",
        "      model2=sm.OLS(data2['target1'],data2.drop(['target1'],axis=1)).fit()\n",
        "      backward_predict = model2.predict(data_backward.drop(['target1'],axis=1))\n",
        "      backward_r2=model2.rsquared\n",
        "      backward_rmse=np.sqrt(np.mean((test_set['target1'] - backward_predict) ** 2 ))\n",
        "      print('변수제거후의 결정계수 :', backward_r2)\n",
        "      print('변수제거후의 RMSE :', backward_rmse)\n",
        "      print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "초기의 결정계수 : 0.9468049274850594\n",
            "초기의 RMSE : 8.29667499984857\n",
            "\n",
            "변수제거후의 결정계수 : 0.9468019394253707\n",
            "변수제거후의 RMSE : 8.322134464189082\n",
            "\n",
            "변수제거후의 결정계수 : 0.9467857849735659\n",
            "변수제거후의 RMSE : 8.25001928276506\n",
            "\n",
            "변수제거후의 결정계수 : 0.9467588865130455\n",
            "변수제거후의 RMSE : 8.123183717312108\n",
            "\n",
            "변수제거후의 결정계수 : 0.9467404906480017\n",
            "변수제거후의 RMSE : 8.070913599403008\n",
            "\n",
            "변수제거후의 결정계수 : 0.9467272869976519\n",
            "변수제거후의 RMSE : 7.995569004885909\n",
            "\n",
            "변수제거후의 결정계수 : 0.9467152085260618\n",
            "변수제거후의 RMSE : 8.012608559145338\n",
            "\n",
            "변수제거후의 결정계수 : 0.9466750222136087\n",
            "변수제거후의 RMSE : 7.954426060486905\n",
            "\n",
            "변수제거후의 결정계수 : 0.9465975560648603\n",
            "변수제거후의 RMSE : 8.096420499068739\n",
            "\n",
            "변수제거후의 결정계수 : 0.9465499108096448\n",
            "변수제거후의 RMSE : 8.135869784918043\n",
            "\n",
            "변수제거후의 결정계수 : 0.9465326442681374\n",
            "변수제거후의 RMSE : 8.161355872196895\n",
            "\n",
            "변수제거후의 결정계수 : 0.946430751747924\n",
            "변수제거후의 RMSE : 8.135648636554407\n",
            "\n",
            "변수제거후의 결정계수 : 0.9462347486051054\n",
            "변수제거후의 RMSE : 7.892179559433625\n",
            "\n",
            "변수제거후의 결정계수 : 0.9459683518589019\n",
            "변수제거후의 RMSE : 7.706195929614585\n",
            "\n",
            "변수제거후의 결정계수 : 0.945692670967076\n",
            "변수제거후의 RMSE : 7.534439819387887\n",
            "\n",
            "변수제거후의 결정계수 : 0.9452420746960747\n",
            "변수제거후의 RMSE : 7.580320902426301\n",
            "\n",
            "변수제거후의 결정계수 : 0.9446614711006677\n",
            "변수제거후의 RMSE : 7.42654805803361\n",
            "\n",
            "변수제거후의 결정계수 : 0.9442552772024178\n",
            "변수제거후의 RMSE : 7.285016006424386\n",
            "\n",
            "변수제거후의 결정계수 : 0.9439036216108474\n",
            "변수제거후의 RMSE : 7.17277974409323\n",
            "\n",
            "변수제거후의 결정계수 : 0.9432014650239081\n",
            "변수제거후의 RMSE : 7.181853103445763\n",
            "\n",
            "변수제거후의 결정계수 : 0.9427447417875088\n",
            "변수제거후의 RMSE : 7.26714547653506\n",
            "\n",
            "변수제거후의 결정계수 : 0.9418943367849038\n",
            "변수제거후의 RMSE : 7.375089916454896\n",
            "\n",
            "변수제거후의 결정계수 : 0.9413328541169064\n",
            "변수제거후의 RMSE : 7.299416755657272\n",
            "\n",
            "변수제거후의 결정계수 : 0.9396477020364117\n",
            "변수제거후의 RMSE : 7.251355465190865\n",
            "\n",
            "변수제거후의 결정계수 : 0.9374590517157584\n",
            "변수제거후의 RMSE : 6.985512170763749\n",
            "\n",
            "변수제거후의 결정계수 : 0.9357293927524647\n",
            "변수제거후의 RMSE : 6.8619994260434805\n",
            "\n",
            "변수제거후의 결정계수 : 0.934399815625989\n",
            "변수제거후의 RMSE : 6.708017309179498\n",
            "\n",
            "변수제거후의 결정계수 : 0.9328883257681219\n",
            "변수제거후의 RMSE : 6.697474047549758\n",
            "\n",
            "변수제거후의 결정계수 : 0.9312987187096861\n",
            "변수제거후의 RMSE : 6.4092062210387475\n",
            "\n",
            "변수제거후의 결정계수 : 0.9294449665369559\n",
            "변수제거후의 RMSE : 6.349518542657199\n",
            "\n",
            "변수제거후의 결정계수 : 0.9279069066002151\n",
            "변수제거후의 RMSE : 6.188571593270978\n",
            "\n",
            "변수제거후의 결정계수 : 0.926411565217822\n",
            "변수제거후의 RMSE : 5.962559885761468\n",
            "\n",
            "변수제거후의 결정계수 : 0.9249559375568974\n",
            "변수제거후의 RMSE : 5.888214172700122\n",
            "\n",
            "변수제거후의 결정계수 : 0.923587328985434\n",
            "변수제거후의 RMSE : 5.851546776359652\n",
            "\n",
            "변수제거후의 결정계수 : 0.9219487530179883\n",
            "변수제거후의 RMSE : 5.797103489327756\n",
            "\n",
            "변수제거후의 결정계수 : 0.9201982152593847\n",
            "변수제거후의 RMSE : 5.650209849861104\n",
            "\n",
            "변수제거후의 결정계수 : 0.9185728575966717\n",
            "변수제거후의 RMSE : 5.656837978738568\n",
            "\n",
            "변수제거후의 결정계수 : 0.9168073920740115\n",
            "변수제거후의 RMSE : 5.5839125874975934\n",
            "\n",
            "변수제거후의 결정계수 : 0.9150368891394639\n",
            "변수제거후의 RMSE : 5.427027843669386\n",
            "\n",
            "변수제거후의 결정계수 : 0.9142099134402913\n",
            "변수제거후의 RMSE : 5.3514772020152135\n",
            "\n",
            "변수제거후의 결정계수 : 0.9133709420558387\n",
            "변수제거후의 RMSE : 5.307271679513249\n",
            "\n",
            "변수제거후의 결정계수 : 0.9124584878660308\n",
            "변수제거후의 RMSE : 5.290542310480278\n",
            "\n",
            "변수제거후의 결정계수 : 0.9112565328627261\n",
            "변수제거후의 RMSE : 5.151037074520866\n",
            "\n",
            "변수제거후의 결정계수 : 0.9098335531614832\n",
            "변수제거후의 RMSE : 5.039234468111087\n",
            "\n",
            "변수제거후의 결정계수 : 0.9084981221581502\n",
            "변수제거후의 RMSE : 5.034409693513419\n",
            "\n",
            "변수제거후의 결정계수 : 0.9076175987180054\n",
            "변수제거후의 RMSE : 5.0019634824688834\n",
            "\n",
            "변수제거후의 결정계수 : 0.9058440248811226\n",
            "변수제거후의 RMSE : 4.899417097155516\n",
            "\n",
            "변수제거후의 결정계수 : 0.9041506180810759\n",
            "변수제거후의 RMSE : 4.826685844769465\n",
            "\n",
            "변수제거후의 결정계수 : 0.901884044412811\n",
            "변수제거후의 RMSE : 4.724204622828496\n",
            "\n",
            "변수제거후의 결정계수 : 0.8997438895294073\n",
            "변수제거후의 RMSE : 4.724369106014396\n",
            "\n",
            "변수제거후의 결정계수 : 0.8972297545224621\n",
            "변수제거후의 RMSE : 4.691979725964281\n",
            "\n",
            "변수제거후의 결정계수 : 0.8951674314819245\n",
            "변수제거후의 RMSE : 4.619651523012462\n",
            "\n",
            "변수제거후의 결정계수 : 0.893549352158609\n",
            "변수제거후의 RMSE : 4.615465260233079\n",
            "\n",
            "변수제거후의 결정계수 : 0.8918974436107406\n",
            "변수제거후의 RMSE : 4.629863236617382\n",
            "\n",
            "변수제거후의 결정계수 : 0.8904041176679784\n",
            "변수제거후의 RMSE : 4.594931631321332\n",
            "\n",
            "변수제거후의 결정계수 : 0.8879536177140969\n",
            "변수제거후의 RMSE : 4.609055485733625\n",
            "\n",
            "변수제거후의 결정계수 : 0.8858095101712378\n",
            "변수제거후의 RMSE : 4.590520606984031\n",
            "\n",
            "변수제거후의 결정계수 : 0.8839296890625595\n",
            "변수제거후의 RMSE : 4.5137258738528265\n",
            "\n",
            "변수제거후의 결정계수 : 0.8807283021758961\n",
            "변수제거후의 RMSE : 4.480090041614903\n",
            "\n",
            "변수제거후의 결정계수 : 0.8777047594704157\n",
            "변수제거후의 RMSE : 4.528572101174862\n",
            "\n",
            "변수제거후의 결정계수 : 0.8748722172144112\n",
            "변수제거후의 RMSE : 4.426613314719553\n",
            "\n",
            "변수제거후의 결정계수 : 0.8706742062714277\n",
            "변수제거후의 RMSE : 4.378294439039629\n",
            "\n",
            "변수제거후의 결정계수 : 0.8676402787934634\n",
            "변수제거후의 RMSE : 4.3047829159731\n",
            "\n",
            "변수제거후의 결정계수 : 0.8637146721648139\n",
            "변수제거후의 RMSE : 4.213380521063383\n",
            "\n",
            "변수제거후의 결정계수 : 0.8599212718936063\n",
            "변수제거후의 RMSE : 4.165611817063495\n",
            "\n",
            "변수제거후의 결정계수 : 0.856481643708659\n",
            "변수제거후의 RMSE : 4.104049930500708\n",
            "\n",
            "변수제거후의 결정계수 : 0.8524143778577865\n",
            "변수제거후의 RMSE : 4.065569152010167\n",
            "\n",
            "변수제거후의 결정계수 : 0.848563205347077\n",
            "변수제거후의 RMSE : 4.055070213440822\n",
            "\n",
            "변수제거후의 결정계수 : 0.843449423607044\n",
            "변수제거후의 RMSE : 4.052824565933195\n",
            "\n",
            "변수제거후의 결정계수 : 0.8398308503069281\n",
            "변수제거후의 RMSE : 3.953025987100829\n",
            "\n",
            "변수제거후의 결정계수 : 0.8354336578947836\n",
            "변수제거후의 RMSE : 3.874298018525272\n",
            "\n",
            "변수제거후의 결정계수 : 0.8320011445669284\n",
            "변수제거후의 RMSE : 3.8012049969459905\n",
            "\n",
            "변수제거후의 결정계수 : 0.827224976402242\n",
            "변수제거후의 RMSE : 3.7011528948130303\n",
            "\n",
            "변수제거후의 결정계수 : 0.8220753388625496\n",
            "변수제거후의 RMSE : 3.712184241098778\n",
            "\n",
            "변수제거후의 결정계수 : 0.8173213148711417\n",
            "변수제거후의 RMSE : 3.6403111033041857\n",
            "\n",
            "변수제거후의 결정계수 : 0.8113950358778502\n",
            "변수제거후의 RMSE : 3.549253267350477\n",
            "\n",
            "변수제거후의 결정계수 : 0.8063167299259839\n",
            "변수제거후의 RMSE : 3.484166089142869\n",
            "\n",
            "변수제거후의 결정계수 : 0.8020609818126447\n",
            "변수제거후의 RMSE : 3.385735743635408\n",
            "\n",
            "변수제거후의 결정계수 : 0.7963363923298857\n",
            "변수제거후의 RMSE : 3.347262655752558\n",
            "\n",
            "변수제거후의 결정계수 : 0.7911976338365547\n",
            "변수제거후의 RMSE : 3.291761700107261\n",
            "\n",
            "변수제거후의 결정계수 : 0.7878824828488926\n",
            "변수제거후의 RMSE : 3.214425983123304\n",
            "\n",
            "변수제거후의 결정계수 : 0.78484124055138\n",
            "변수제거후의 RMSE : 3.1714826854003313\n",
            "\n",
            "변수제거후의 결정계수 : 0.7821613094897403\n",
            "변수제거후의 RMSE : 3.145805988911833\n",
            "\n",
            "변수제거후의 결정계수 : 0.7782616482541498\n",
            "변수제거후의 RMSE : 3.1166128399634743\n",
            "\n",
            "변수제거후의 결정계수 : 0.7737130009381824\n",
            "변수제거후의 RMSE : 3.0595382765027104\n",
            "\n",
            "변수제거후의 결정계수 : 0.7688003821547871\n",
            "변수제거후의 RMSE : 2.9799449049564166\n",
            "\n",
            "변수제거후의 결정계수 : 0.7642284847654505\n",
            "변수제거후의 RMSE : 2.957707431262167\n",
            "\n",
            "변수제거후의 결정계수 : 0.7603436593814283\n",
            "변수제거후의 RMSE : 2.8775853858329836\n",
            "\n",
            "변수제거후의 결정계수 : 0.7559715443749453\n",
            "변수제거후의 RMSE : 2.868452467110483\n",
            "\n",
            "변수제거후의 결정계수 : 0.750924839725045\n",
            "변수제거후의 RMSE : 2.8124008889480594\n",
            "\n",
            "변수제거후의 결정계수 : 0.7469570929071485\n",
            "변수제거후의 RMSE : 2.7926273984401835\n",
            "\n",
            "변수제거후의 결정계수 : 0.7437641925914509\n",
            "변수제거후의 RMSE : 2.76516870062153\n",
            "\n",
            "변수제거후의 결정계수 : 0.7382062929054223\n",
            "변수제거후의 RMSE : 2.693630960945265\n",
            "\n",
            "변수제거후의 결정계수 : 0.7334299841309813\n",
            "변수제거후의 RMSE : 2.646414705554296\n",
            "\n",
            "변수제거후의 결정계수 : 0.7282158554141707\n",
            "변수제거후의 RMSE : 2.643744497091588\n",
            "\n",
            "변수제거후의 결정계수 : 0.722525523268531\n",
            "변수제거후의 RMSE : 2.6092678110580345\n",
            "\n",
            "변수제거후의 결정계수 : 0.7183917388448826\n",
            "변수제거후의 RMSE : 2.559813721689577\n",
            "\n",
            "변수제거후의 결정계수 : 0.7143903344661947\n",
            "변수제거후의 RMSE : 2.545749987843881\n",
            "\n",
            "변수제거후의 결정계수 : 0.7113687439045097\n",
            "변수제거후의 RMSE : 2.521888533686244\n",
            "\n",
            "변수제거후의 결정계수 : 0.7089824958269421\n",
            "변수제거후의 RMSE : 2.518706888191297\n",
            "\n",
            "변수제거후의 결정계수 : 0.7056783827400536\n",
            "변수제거후의 RMSE : 2.486913495455054\n",
            "\n",
            "변수제거후의 결정계수 : 0.7020345090997879\n",
            "변수제거후의 RMSE : 2.4649813437104235\n",
            "\n",
            "변수제거후의 결정계수 : 0.6986092817263967\n",
            "변수제거후의 RMSE : 2.4607899424735464\n",
            "\n",
            "변수제거후의 결정계수 : 0.6947822586541583\n",
            "변수제거후의 RMSE : 2.4365006026763676\n",
            "\n",
            "변수제거후의 결정계수 : 0.6907085554859451\n",
            "변수제거후의 RMSE : 2.398463068991178\n",
            "\n",
            "변수제거후의 결정계수 : 0.6861413051041769\n",
            "변수제거후의 RMSE : 2.3701026370823475\n",
            "\n",
            "변수제거후의 결정계수 : 0.6816415631064536\n",
            "변수제거후의 RMSE : 2.3431842163994854\n",
            "\n",
            "변수제거후의 결정계수 : 0.6765226792502514\n",
            "변수제거후의 RMSE : 2.3036958944894543\n",
            "\n",
            "변수제거후의 결정계수 : 0.6692020478843813\n",
            "변수제거후의 RMSE : 2.218348632387784\n",
            "\n",
            "변수제거후의 결정계수 : 0.6638208594563185\n",
            "변수제거후의 RMSE : 2.1722886207176346\n",
            "\n",
            "변수제거후의 결정계수 : 0.6582867141796533\n",
            "변수제거후의 RMSE : 2.1488166386165184\n",
            "\n",
            "변수제거후의 결정계수 : 0.653429785420655\n",
            "변수제거후의 RMSE : 2.1186020318140737\n",
            "\n",
            "변수제거후의 결정계수 : 0.6490074173448303\n",
            "변수제거후의 RMSE : 2.1153467321983412\n",
            "\n",
            "변수제거후의 결정계수 : 0.6447444998194318\n",
            "변수제거후의 RMSE : 2.0810370711310746\n",
            "\n",
            "변수제거후의 결정계수 : 0.6399001041256279\n",
            "변수제거후의 RMSE : 2.0494197344803995\n",
            "\n",
            "변수제거후의 결정계수 : 0.6354062362571415\n",
            "변수제거후의 RMSE : 2.0316822667129717\n",
            "\n",
            "변수제거후의 결정계수 : 0.629810061526286\n",
            "변수제거후의 RMSE : 1.9892992483304162\n",
            "\n",
            "변수제거후의 결정계수 : 0.623298482117675\n",
            "변수제거후의 RMSE : 1.9714073911740633\n",
            "\n",
            "변수제거후의 결정계수 : 0.6171670186942069\n",
            "변수제거후의 RMSE : 1.9553401009426312\n",
            "\n",
            "변수제거후의 결정계수 : 0.6108458055294999\n",
            "변수제거후의 RMSE : 1.902729943497778\n",
            "\n",
            "변수제거후의 결정계수 : 0.6052529680726322\n",
            "변수제거후의 RMSE : 1.862904538514342\n",
            "\n",
            "변수제거후의 결정계수 : 0.598805675473376\n",
            "변수제거후의 RMSE : 1.8572605100893376\n",
            "\n",
            "변수제거후의 결정계수 : 0.5944082194580831\n",
            "변수제거후의 RMSE : 1.8552904287941687\n",
            "\n",
            "변수제거후의 결정계수 : 0.589661529251432\n",
            "변수제거후의 RMSE : 1.837234173237111\n",
            "\n",
            "변수제거후의 결정계수 : 0.5839397047967181\n",
            "변수제거후의 RMSE : 1.8188352376484935\n",
            "\n",
            "변수제거후의 결정계수 : 0.5799395504547759\n",
            "변수제거후의 RMSE : 1.799759764276304\n",
            "\n",
            "변수제거후의 결정계수 : 0.5737298229068563\n",
            "변수제거후의 RMSE : 1.760020674393192\n",
            "\n",
            "변수제거후의 결정계수 : 0.5663768726700954\n",
            "변수제거후의 RMSE : 1.741577873018764\n",
            "\n",
            "변수제거후의 결정계수 : 0.5604303848115082\n",
            "변수제거후의 RMSE : 1.7118907855537318\n",
            "\n",
            "변수제거후의 결정계수 : 0.5544549965351238\n",
            "변수제거후의 RMSE : 1.7152010076583055\n",
            "\n",
            "변수제거후의 결정계수 : 0.5478940928744025\n",
            "변수제거후의 RMSE : 1.665008005730676\n",
            "\n",
            "변수제거후의 결정계수 : 0.5421236800581855\n",
            "변수제거후의 RMSE : 1.634819855793102\n",
            "\n",
            "변수제거후의 결정계수 : 0.5361004990000509\n",
            "변수제거후의 RMSE : 1.5852169313865594\n",
            "\n",
            "변수제거후의 결정계수 : 0.5301041382718166\n",
            "변수제거후의 RMSE : 1.5433315496927662\n",
            "\n",
            "변수제거후의 결정계수 : 0.5250453354255069\n",
            "변수제거후의 RMSE : 1.5049659704631835\n",
            "\n",
            "변수제거후의 결정계수 : 0.518552429701856\n",
            "변수제거후의 RMSE : 1.4811043646233437\n",
            "\n",
            "변수제거후의 결정계수 : 0.5115186953217473\n",
            "변수제거후의 RMSE : 1.4675761940511316\n",
            "\n",
            "변수제거후의 결정계수 : 0.504052596436507\n",
            "변수제거후의 RMSE : 1.4477411462786356\n",
            "\n",
            "변수제거후의 결정계수 : 0.4963228802250177\n",
            "변수제거후의 RMSE : 1.4454175613824891\n",
            "\n",
            "변수제거후의 결정계수 : 0.4869649167202861\n",
            "변수제거후의 RMSE : 1.3883994311771424\n",
            "\n",
            "변수제거후의 결정계수 : 0.4787568804973056\n",
            "변수제거후의 RMSE : 1.3745283666199937\n",
            "\n",
            "변수제거후의 결정계수 : 0.4721218065376468\n",
            "변수제거후의 RMSE : 1.3714325355432258\n",
            "\n",
            "변수제거후의 결정계수 : 0.46224057734762813\n",
            "변수제거후의 RMSE : 1.3237765937905919\n",
            "\n",
            "변수제거후의 결정계수 : 0.4539099735462673\n",
            "변수제거후의 RMSE : 1.306359942770603\n",
            "\n",
            "변수제거후의 결정계수 : 0.4437385194359694\n",
            "변수제거후의 RMSE : 1.284314589316465\n",
            "\n",
            "변수제거후의 결정계수 : 0.43481992045179263\n",
            "변수제거후의 RMSE : 1.2800153774009122\n",
            "\n",
            "변수제거후의 결정계수 : 0.4275146017408543\n",
            "변수제거후의 RMSE : 1.2705315004068687\n",
            "\n",
            "변수제거후의 결정계수 : 0.41843704075719446\n",
            "변수제거후의 RMSE : 1.268189393812425\n",
            "\n",
            "변수제거후의 결정계수 : 0.4087888809223692\n",
            "변수제거후의 RMSE : 1.225365925301354\n",
            "\n",
            "변수제거후의 결정계수 : 0.40158684629044883\n",
            "변수제거후의 RMSE : 1.2080830334114172\n",
            "\n",
            "변수제거후의 결정계수 : 0.39412359733921487\n",
            "변수제거후의 RMSE : 1.211741777940931\n",
            "\n",
            "변수제거후의 결정계수 : 0.3864403893494145\n",
            "변수제거후의 RMSE : 1.1980438144303434\n",
            "\n",
            "변수제거후의 결정계수 : 0.37713919859948397\n",
            "변수제거후의 RMSE : 1.2067117219938104\n",
            "\n",
            "변수제거후의 결정계수 : 0.36765222265637865\n",
            "변수제거후의 RMSE : 1.1960302877778897\n",
            "\n",
            "변수제거후의 결정계수 : 0.3584128343117359\n",
            "변수제거후의 RMSE : 1.191332169063168\n",
            "\n",
            "변수제거후의 결정계수 : 0.34886620382705646\n",
            "변수제거후의 RMSE : 1.2081773770218702\n",
            "\n",
            "변수제거후의 결정계수 : 0.34024220914238357\n",
            "변수제거후의 RMSE : 1.2020322132775207\n",
            "\n",
            "변수제거후의 결정계수 : 0.32991909208124437\n",
            "변수제거후의 RMSE : 1.211709691798115\n",
            "\n",
            "변수제거후의 결정계수 : 0.32059825164344025\n",
            "변수제거후의 RMSE : 1.2092804117716134\n",
            "\n",
            "변수제거후의 결정계수 : 0.30935318939938916\n",
            "변수제거후의 RMSE : 1.1985432683144728\n",
            "\n",
            "변수제거후의 결정계수 : 0.29666897780989854\n",
            "변수제거후의 RMSE : 1.191968220003027\n",
            "\n",
            "변수제거후의 결정계수 : 0.2803740169497898\n",
            "변수제거후의 RMSE : 1.168271382999894\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbew4_9PpE8V"
      },
      "source": [
        "# 최종적으로는 다음과 같은 변수들만 남게 되었다.\n",
        "\n",
        "결정계수는 전진선택법보다 조금 낮게 나왔으나, RMSE에서는 후진소거법이 좀더 나은 모습을 보여준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "Y9JH9P3bkOYW",
        "outputId": "fd7a3c07-96fa-4f67-d583-b713d9267607"
      },
      "source": [
        "data_backward"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target1</th>\n",
              "      <th>7</th>\n",
              "      <th>17</th>\n",
              "      <th>21</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>48</th>\n",
              "      <th>86</th>\n",
              "      <th>134</th>\n",
              "      <th>145</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>-1.479</td>\n",
              "      <td>1.555</td>\n",
              "      <td>-0.329</td>\n",
              "      <td>0.805</td>\n",
              "      <td>-0.396</td>\n",
              "      <td>-0.181</td>\n",
              "      <td>1.091</td>\n",
              "      <td>0.205</td>\n",
              "      <td>-0.538</td>\n",
              "      <td>0.075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>0.386</td>\n",
              "      <td>-0.197</td>\n",
              "      <td>-0.217</td>\n",
              "      <td>0.744</td>\n",
              "      <td>1.359</td>\n",
              "      <td>-0.835</td>\n",
              "      <td>0.598</td>\n",
              "      <td>-1.909</td>\n",
              "      <td>0.015</td>\n",
              "      <td>-0.132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>0.463</td>\n",
              "      <td>1.028</td>\n",
              "      <td>-1.469</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.984</td>\n",
              "      <td>-0.795</td>\n",
              "      <td>0.404</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.682</td>\n",
              "      <td>-0.203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>-0.617</td>\n",
              "      <td>0.472</td>\n",
              "      <td>0.488</td>\n",
              "      <td>-0.018</td>\n",
              "      <td>1.123</td>\n",
              "      <td>-0.440</td>\n",
              "      <td>0.153</td>\n",
              "      <td>0.639</td>\n",
              "      <td>-0.843</td>\n",
              "      <td>-0.865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>-1.602</td>\n",
              "      <td>1.092</td>\n",
              "      <td>-0.941</td>\n",
              "      <td>-2.648</td>\n",
              "      <td>0.196</td>\n",
              "      <td>-0.482</td>\n",
              "      <td>1.062</td>\n",
              "      <td>-0.821</td>\n",
              "      <td>-1.796</td>\n",
              "      <td>-1.753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.526</td>\n",
              "      <td>0.165</td>\n",
              "      <td>-0.192</td>\n",
              "      <td>-0.676</td>\n",
              "      <td>0.743</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.331</td>\n",
              "      <td>-1.396</td>\n",
              "      <td>-0.222</td>\n",
              "      <td>1.023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>-1.071</td>\n",
              "      <td>-0.783</td>\n",
              "      <td>0.050</td>\n",
              "      <td>-1.392</td>\n",
              "      <td>-1.324</td>\n",
              "      <td>-0.030</td>\n",
              "      <td>1.342</td>\n",
              "      <td>1.259</td>\n",
              "      <td>-0.946</td>\n",
              "      <td>0.977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>-1.299</td>\n",
              "      <td>0.554</td>\n",
              "      <td>-0.478</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>-0.462</td>\n",
              "      <td>1.179</td>\n",
              "      <td>0.393</td>\n",
              "      <td>-0.419</td>\n",
              "      <td>-0.115</td>\n",
              "      <td>-0.506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.668</td>\n",
              "      <td>0.965</td>\n",
              "      <td>-0.228</td>\n",
              "      <td>0.802</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.578</td>\n",
              "      <td>-0.689</td>\n",
              "      <td>-0.186</td>\n",
              "      <td>0.129</td>\n",
              "      <td>1.108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-0.611</td>\n",
              "      <td>-0.176</td>\n",
              "      <td>0.391</td>\n",
              "      <td>-0.120</td>\n",
              "      <td>0.774</td>\n",
              "      <td>-0.042</td>\n",
              "      <td>-0.359</td>\n",
              "      <td>-0.370</td>\n",
              "      <td>-0.376</td>\n",
              "      <td>0.831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>75 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     target1      7     17     21     29     30     48     86    134    145\n",
              "94    -1.479  1.555 -0.329  0.805 -0.396 -0.181  1.091  0.205 -0.538  0.075\n",
              "124    0.386 -0.197 -0.217  0.744  1.359 -0.835  0.598 -1.909  0.015 -0.132\n",
              "239    0.463  1.028 -1.469  0.076  0.984 -0.795  0.404  0.450  0.682 -0.203\n",
              "25    -0.617  0.472  0.488 -0.018  1.123 -0.440  0.153  0.639 -0.843 -0.865\n",
              "98    -1.602  1.092 -0.941 -2.648  0.196 -0.482  1.062 -0.821 -1.796 -1.753\n",
              "..       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
              "47     0.526  0.165 -0.192 -0.676  0.743  0.533  0.331 -1.396 -0.222  1.023\n",
              "83    -1.071 -0.783  0.050 -1.392 -1.324 -0.030  1.342  1.259 -0.946  0.977\n",
              "102   -1.299  0.554 -0.478 -0.205 -0.462  1.179  0.393 -0.419 -0.115 -0.506\n",
              "7      0.668  0.965 -0.228  0.802  0.143  0.578 -0.689 -0.186  0.129  1.108\n",
              "21    -0.611 -0.176  0.391 -0.120  0.774 -0.042 -0.359 -0.370 -0.376  0.831\n",
              "\n",
              "[75 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n-wIj5lpMkr"
      },
      "source": [
        "# 단계선택법\n",
        "상관계수가 제일 높게나온 변수를 초기에 넣어준후, 변수를 하나씩 추가하며 기존에 있는 변수와 들어오는 변수의 유의성을 검정통계량을 통해 살핀다.\n",
        "\n",
        "만약 들어오는 변수가 유의하다 할지라도, 기존에 있던 변수들에게 유의성에 있어서 영향을 주게되면 탈락시킨다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_l7bBH8nANjY",
        "outputId": "9a1bee14-03a1-4e97-db68-0332fa81a6cb"
      },
      "source": [
        "# 단계선택법\n",
        "data2=train_set.copy()\n",
        "data_step=test_set.copy()\n",
        "data_corr2=abs(data_corr)\n",
        "step=pd.DataFrame()\n",
        "step1=pd.DataFrame()\n",
        "for num in range(1,int(len(data2.T))):\n",
        "  if num == 1 :\n",
        "    data_corr2=pd.DataFrame(data2.corr().iloc[0])\n",
        "    data_corr2=data_corr2.drop(['target1'],axis=0)\n",
        "    cor=data_corr2[data_corr2['target1'] == data_corr2['target1'].max()].index[0]\n",
        "    variable=pd.DataFrame(data2[cor])\n",
        "    variable1=pd.DataFrame(data_step[cor])\n",
        "    model3=sm.OLS(data2['target1'],variable).fit()\n",
        "  \n",
        "    if model3.pvalues.values[-1] >= 0.05:\n",
        "       data2=data2.drop([cor],axis=1)\n",
        "    else:\n",
        "      step_predict = model3.predict(variable1)\n",
        "      step_r2=model3.rsquared\n",
        "      step_rmse=np.sqrt(np.mean((test_set['target1'] - step_predict) ** 2 ))\n",
        "      print('초기변수의 결정계수 :', step_r2)\n",
        "      print('초기변수의 RMSE :', step_rmse)\n",
        "      print()\n",
        "      step=pd.concat([step,variable], axis=1)\n",
        "      step1=pd.concat([step1,variable1], axis=1)\n",
        "      data2=data2.drop([cor],axis=1)\n",
        "  else:\n",
        "    data_corr2=abs(pd.DataFrame(data2.corr().iloc[0]))\n",
        "    data_corr2=data_corr2.drop(['target1'],axis=0)\n",
        "    cor=data_corr2[data_corr2['target1'] == data_corr2['target1'].max()].index[0]\n",
        "    variable=pd.DataFrame(data2[cor])\n",
        "    variable1=pd.DataFrame(data_step[cor])\n",
        "    step=pd.concat([step,variable],axis=1)\n",
        "    step1=pd.concat([step1,variable1], axis=1)\n",
        "    model3=sm.OLS(data2['target1'],step).fit()\n",
        "    \n",
        "\n",
        "    if len(model3.pvalues[model3.pvalues >= 0.05]) != 0:\n",
        "      step=step.drop([cor],axis=1)\n",
        "      step1=step1.drop([cor],axis=1)\n",
        "      data2=data2.drop([cor],axis=1)\n",
        "      \n",
        "    else: \n",
        "      step_predict = model3.predict(step1)\n",
        "      step_r2=model3.rsquared\n",
        "      step_rmse=np.sqrt(np.mean((test_set['target1'] - step_predict) ** 2 ))\n",
        "      print('변수선택후의 결정계수 :', step_r2)\n",
        "      print('변수선택후의 RMSE :', step_rmse)\n",
        "      print()\n",
        "      data2=data2.drop([cor],axis=1) \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "초기변수의 결정계수 : 0.05548951523342183\n",
            "초기변수의 RMSE : 1.0447493699766581\n",
            "\n",
            "변수선택후의 결정계수 : 0.10974808579502837\n",
            "변수선택후의 RMSE : 1.0485303748792427\n",
            "\n",
            "변수선택후의 결정계수 : 0.1406939103699859\n",
            "변수선택후의 RMSE : 1.1021573000985192\n",
            "\n",
            "변수선택후의 결정계수 : 0.16618283384030608\n",
            "변수선택후의 RMSE : 1.1169615722572583\n",
            "\n",
            "변수선택후의 결정계수 : 0.19264620691747092\n",
            "변수선택후의 RMSE : 1.1178872936915505\n",
            "\n",
            "변수선택후의 결정계수 : 0.2167786100997957\n",
            "변수선택후의 RMSE : 1.0998983235591446\n",
            "\n",
            "변수선택후의 결정계수 : 0.2408240386846927\n",
            "변수선택후의 RMSE : 1.097108054055377\n",
            "\n",
            "변수선택후의 결정계수 : 0.25980326803535714\n",
            "변수선택후의 RMSE : 1.1474443661257148\n",
            "\n",
            "변수선택후의 결정계수 : 0.2788500161394277\n",
            "변수선택후의 RMSE : 1.1547281964112532\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-27UCkR2pcTZ"
      },
      "source": [
        "# 최종적으로는 다음과 같은 변수들만 선택되었다.\n",
        "결정계수는 후진소거법보다 조금 떨어지지만, RMSE는 나은 모습을 보여준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "H5sXDeniGGDw",
        "outputId": "51bb97da-dede-4e5e-98c2-4c2b8eb33d71"
      },
      "source": [
        "step"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>86</th>\n",
              "      <th>30</th>\n",
              "      <th>164</th>\n",
              "      <th>17</th>\n",
              "      <th>20</th>\n",
              "      <th>48</th>\n",
              "      <th>134</th>\n",
              "      <th>64</th>\n",
              "      <th>123</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.507</td>\n",
              "      <td>2.389</td>\n",
              "      <td>0.127</td>\n",
              "      <td>-0.048</td>\n",
              "      <td>0.269</td>\n",
              "      <td>-0.968</td>\n",
              "      <td>0.028</td>\n",
              "      <td>-0.364</td>\n",
              "      <td>-0.370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>-1.451</td>\n",
              "      <td>-0.118</td>\n",
              "      <td>1.012</td>\n",
              "      <td>0.436</td>\n",
              "      <td>-0.731</td>\n",
              "      <td>0.098</td>\n",
              "      <td>-0.425</td>\n",
              "      <td>0.434</td>\n",
              "      <td>0.242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0.559</td>\n",
              "      <td>0.725</td>\n",
              "      <td>-1.245</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>0.003</td>\n",
              "      <td>-0.456</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>0.833</td>\n",
              "      <td>-2.081</td>\n",
              "      <td>-0.735</td>\n",
              "      <td>0.077</td>\n",
              "      <td>-0.810</td>\n",
              "      <td>0.078</td>\n",
              "      <td>0.535</td>\n",
              "      <td>-1.701</td>\n",
              "      <td>-0.354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>-0.357</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.223</td>\n",
              "      <td>-0.488</td>\n",
              "      <td>-0.336</td>\n",
              "      <td>-0.061</td>\n",
              "      <td>0.973</td>\n",
              "      <td>1.948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1.088</td>\n",
              "      <td>-1.187</td>\n",
              "      <td>-2.229</td>\n",
              "      <td>0.412</td>\n",
              "      <td>-1.165</td>\n",
              "      <td>1.910</td>\n",
              "      <td>0.180</td>\n",
              "      <td>-0.440</td>\n",
              "      <td>-0.639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>0.144</td>\n",
              "      <td>-1.801</td>\n",
              "      <td>-1.236</td>\n",
              "      <td>-1.796</td>\n",
              "      <td>-1.733</td>\n",
              "      <td>0.897</td>\n",
              "      <td>3.032</td>\n",
              "      <td>-1.079</td>\n",
              "      <td>-0.617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>-1.677</td>\n",
              "      <td>-0.652</td>\n",
              "      <td>-1.126</td>\n",
              "      <td>-0.469</td>\n",
              "      <td>-0.367</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.566</td>\n",
              "      <td>-1.603</td>\n",
              "      <td>0.609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-1.622</td>\n",
              "      <td>-0.760</td>\n",
              "      <td>-1.007</td>\n",
              "      <td>0.262</td>\n",
              "      <td>0.109</td>\n",
              "      <td>-0.578</td>\n",
              "      <td>1.159</td>\n",
              "      <td>-0.621</td>\n",
              "      <td>0.389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>1.738</td>\n",
              "      <td>-1.468</td>\n",
              "      <td>-1.158</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.518</td>\n",
              "      <td>-0.677</td>\n",
              "      <td>0.835</td>\n",
              "      <td>-0.062</td>\n",
              "      <td>1.197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        86     30    164     17     20     48    134     64    123\n",
              "36   0.507  2.389  0.127 -0.048  0.269 -0.968  0.028 -0.364 -0.370\n",
              "46  -1.451 -0.118  1.012  0.436 -0.731  0.098 -0.425  0.434  0.242\n",
              "97   0.559  0.725 -1.245 -0.918  0.003 -0.456 -0.374  0.184  0.882\n",
              "143  0.833 -2.081 -0.735  0.077 -0.810  0.078  0.535 -1.701 -0.354\n",
              "112 -0.357  0.920  0.731  0.223 -0.488 -0.336 -0.061  0.973  1.948\n",
              "..     ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
              "33   1.088 -1.187 -2.229  0.412 -1.165  1.910  0.180 -0.440 -0.639\n",
              "183  0.144 -1.801 -1.236 -1.796 -1.733  0.897  3.032 -1.079 -0.617\n",
              "236 -1.677 -0.652 -1.126 -0.469 -0.367  0.992  0.566 -1.603  0.609\n",
              "15  -1.622 -0.760 -1.007  0.262  0.109 -0.578  1.159 -0.621  0.389\n",
              "201  1.738 -1.468 -1.158  0.003  0.518 -0.677  0.835 -0.062  1.197\n",
              "\n",
              "[175 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVY77zukpul6"
      },
      "source": [
        "# 라쏘 변수선택법\n",
        "알파 값을 0에서 1까지 0.01단위로 변화시키며 결정계수와 RMSE를 살펴본다.\n",
        "\n",
        "제약식에서 0이되는 변수들을 제거시키고, 남은 유의한 변수들로만 모델을 구성한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SecUArEkGhSB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a03d0740-305e-4fe6-e210-15b2da87f3a5"
      },
      "source": [
        "lasso_set=pd.DataFrame()\n",
        "for alpha_value in np.arange(0, 1.01, 0.01):\n",
        "  alpha_value=alpha_value\n",
        "  lasso=Lasso(alpha= alpha_value)\n",
        "  data2=train_set.copy()\n",
        "  data_lasso=test_set.copy()\n",
        "  lasso.fit(data2.drop(['target1'],axis=1),data2['target1'])\n",
        "  if np.sum(lasso.coef_ != 0) != 0:\n",
        "    lasso_predict=lasso.predict(test_set.drop(['target1'],axis=1))\n",
        "    lasso_rmse=np.sqrt(np.mean((test_set['target1'] - lasso_predict) ** 2 ))\n",
        "    lasso_a=alpha_value\n",
        "    lasso_r2=lasso.score(data2.drop(['target1'],axis=1), data2['target1'])\n",
        "    lasso_var=pd.DataFrame([np.sum(lasso.coef_ != 0)])\n",
        "    lasso_rmse = pd.DataFrame([lasso_rmse])\n",
        "    lasso_r2 =pd.DataFrame([lasso_r2])\n",
        "    lasso_a = pd.DataFrame([lasso_a])\n",
        "    lasso_set0 = pd.concat([lasso_a,lasso_var,lasso_rmse,lasso_r2],axis=1)\n",
        "    lasso_set=pd.concat([lasso_set,lasso_set0],axis=0)\n",
        "    lasso_set0=pd.DataFrame()\n",
        "    print('알파 값 :',str(lasso_a))\n",
        "    print('사용된 변수 개수 :', str(np.sum(lasso.coef_ != 0)))\n",
        "    print('RMSE :',str(lasso_rmse))\n",
        "    print('결정계수 :',str(lasso_r2))\n",
        "    print()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.01\n",
            "사용된 변수 개수 : 129\n",
            "RMSE :           0\n",
            "0  1.511325\n",
            "결정계수 :           0\n",
            "0  0.805575\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.02\n",
            "사용된 변수 개수 : 100\n",
            "RMSE :           0\n",
            "0  1.259824\n",
            "결정계수 :           0\n",
            "0  0.692919\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.03\n",
            "사용된 변수 개수 : 86\n",
            "RMSE :           0\n",
            "0  1.192264\n",
            "결정계수 :           0\n",
            "0  0.597287\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.04\n",
            "사용된 변수 개수 : 65\n",
            "RMSE :           0\n",
            "0  1.150352\n",
            "결정계수 :           0\n",
            "0  0.524297\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.05\n",
            "사용된 변수 개수 : 51\n",
            "RMSE :           0\n",
            "0  1.113927\n",
            "결정계수 :           0\n",
            "0  0.463278\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.06\n",
            "사용된 변수 개수 : 44\n",
            "RMSE :           0\n",
            "0  1.091547\n",
            "결정계수 :           0\n",
            "0  0.406057\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.07\n",
            "사용된 변수 개수 : 35\n",
            "RMSE :           0\n",
            "0  1.075764\n",
            "결정계수 :           0\n",
            "0  0.353188\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.08\n",
            "사용된 변수 개수 : 28\n",
            "RMSE :           0\n",
            "0  1.064331\n",
            "결정계수 :           0\n",
            "0  0.306831\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.09\n",
            "사용된 변수 개수 : 23\n",
            "RMSE :           0\n",
            "0  1.053898\n",
            "결정계수 :           0\n",
            "0  0.264004\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.1\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.046043\n",
            "결정계수 :           0\n",
            "0  0.227495\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.11\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.038797\n",
            "결정계수 :           0\n",
            "0  0.192563\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.12\n",
            "사용된 변수 개수 : 13\n",
            "RMSE :           0\n",
            "0  1.031536\n",
            "결정계수 :           0\n",
            "0  0.157832\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.13\n",
            "사용된 변수 개수 : 11\n",
            "RMSE :           0\n",
            "0  1.024211\n",
            "결정계수 :           0\n",
            "0  0.124944\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.14\n",
            "사용된 변수 개수 : 8\n",
            "RMSE :           0\n",
            "0  1.019056\n",
            "결정계수 :           0\n",
            "0  0.099461\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.15\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.015084\n",
            "결정계수 :           0\n",
            "0  0.082306\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.16\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.010537\n",
            "결정계수 :           0\n",
            "0  0.070857\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.17\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.006399\n",
            "결정계수 :           0\n",
            "0  0.059603\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.18\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002989\n",
            "결정계수 :           0\n",
            "0  0.050022\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.19\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  1.000357\n",
            "결정계수 :           0\n",
            "0  0.040557\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.2\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  1.000022\n",
            "결정계수 :           0\n",
            "0  0.033214\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.21\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999877\n",
            "결정계수 :           0\n",
            "0  0.025496\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.22\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999923\n",
            "결정계수 :         0\n",
            "0  0.0174\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.23\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  1.000159\n",
            "결정계수 :           0\n",
            "0  0.008929\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.24\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999923\n",
            "결정계수 :          0\n",
            "0  0.00322\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGfDVu6qqK20"
      },
      "source": [
        "# 이 테이블에서 number는 사용된 변수를 말한다.\n",
        "\n",
        "라쏘 선택의 경우 전체적으로 알파값이 0.04~0.08일때 결정계수와 rmse가 위의 전진선택, 후진소거, 단계선택보다 뛰어난 모습을 보여준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "KOtgSRZXGvcc",
        "outputId": "399981cb-e50f-461f-d99e-9d7a1fa5959d"
      },
      "source": [
        "lasso_set.columns=['alpha','number','rmse','r2']\n",
        "lasso_set.index=lasso_set['alpha']\n",
        "lasso_set"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>number</th>\n",
              "      <th>rmse</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alpha</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.00</th>\n",
              "      <td>0.00</td>\n",
              "      <td>170</td>\n",
              "      <td>5.373803</td>\n",
              "      <td>0.942649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.01</th>\n",
              "      <td>0.01</td>\n",
              "      <td>129</td>\n",
              "      <td>1.511325</td>\n",
              "      <td>0.805575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.02</th>\n",
              "      <td>0.02</td>\n",
              "      <td>100</td>\n",
              "      <td>1.259824</td>\n",
              "      <td>0.692919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.03</th>\n",
              "      <td>0.03</td>\n",
              "      <td>86</td>\n",
              "      <td>1.192264</td>\n",
              "      <td>0.597287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.04</th>\n",
              "      <td>0.04</td>\n",
              "      <td>65</td>\n",
              "      <td>1.150352</td>\n",
              "      <td>0.524297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.05</th>\n",
              "      <td>0.05</td>\n",
              "      <td>51</td>\n",
              "      <td>1.113927</td>\n",
              "      <td>0.463278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.06</th>\n",
              "      <td>0.06</td>\n",
              "      <td>44</td>\n",
              "      <td>1.091547</td>\n",
              "      <td>0.406057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.07</th>\n",
              "      <td>0.07</td>\n",
              "      <td>35</td>\n",
              "      <td>1.075764</td>\n",
              "      <td>0.353188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.08</th>\n",
              "      <td>0.08</td>\n",
              "      <td>28</td>\n",
              "      <td>1.064331</td>\n",
              "      <td>0.306831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.09</th>\n",
              "      <td>0.09</td>\n",
              "      <td>23</td>\n",
              "      <td>1.053898</td>\n",
              "      <td>0.264004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.10</th>\n",
              "      <td>0.10</td>\n",
              "      <td>17</td>\n",
              "      <td>1.046043</td>\n",
              "      <td>0.227495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.11</th>\n",
              "      <td>0.11</td>\n",
              "      <td>14</td>\n",
              "      <td>1.038797</td>\n",
              "      <td>0.192563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.12</th>\n",
              "      <td>0.12</td>\n",
              "      <td>13</td>\n",
              "      <td>1.031536</td>\n",
              "      <td>0.157832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.13</th>\n",
              "      <td>0.13</td>\n",
              "      <td>11</td>\n",
              "      <td>1.024211</td>\n",
              "      <td>0.124944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.14</th>\n",
              "      <td>0.14</td>\n",
              "      <td>8</td>\n",
              "      <td>1.019056</td>\n",
              "      <td>0.099461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.15</th>\n",
              "      <td>0.15</td>\n",
              "      <td>5</td>\n",
              "      <td>1.015084</td>\n",
              "      <td>0.082306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.16</th>\n",
              "      <td>0.16</td>\n",
              "      <td>4</td>\n",
              "      <td>1.010537</td>\n",
              "      <td>0.070857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.17</th>\n",
              "      <td>0.17</td>\n",
              "      <td>3</td>\n",
              "      <td>1.006399</td>\n",
              "      <td>0.059603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.18</th>\n",
              "      <td>0.18</td>\n",
              "      <td>3</td>\n",
              "      <td>1.002989</td>\n",
              "      <td>0.050022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.19</th>\n",
              "      <td>0.19</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000357</td>\n",
              "      <td>0.040557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.20</th>\n",
              "      <td>0.20</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000022</td>\n",
              "      <td>0.033214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.21</th>\n",
              "      <td>0.21</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999877</td>\n",
              "      <td>0.025496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.22</th>\n",
              "      <td>0.22</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999923</td>\n",
              "      <td>0.017400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.23</th>\n",
              "      <td>0.23</td>\n",
              "      <td>2</td>\n",
              "      <td>1.000159</td>\n",
              "      <td>0.008929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.24</th>\n",
              "      <td>0.24</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999923</td>\n",
              "      <td>0.003220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       alpha  number      rmse        r2\n",
              "alpha                                   \n",
              "0.00    0.00     170  5.373803  0.942649\n",
              "0.01    0.01     129  1.511325  0.805575\n",
              "0.02    0.02     100  1.259824  0.692919\n",
              "0.03    0.03      86  1.192264  0.597287\n",
              "0.04    0.04      65  1.150352  0.524297\n",
              "0.05    0.05      51  1.113927  0.463278\n",
              "0.06    0.06      44  1.091547  0.406057\n",
              "0.07    0.07      35  1.075764  0.353188\n",
              "0.08    0.08      28  1.064331  0.306831\n",
              "0.09    0.09      23  1.053898  0.264004\n",
              "0.10    0.10      17  1.046043  0.227495\n",
              "0.11    0.11      14  1.038797  0.192563\n",
              "0.12    0.12      13  1.031536  0.157832\n",
              "0.13    0.13      11  1.024211  0.124944\n",
              "0.14    0.14       8  1.019056  0.099461\n",
              "0.15    0.15       5  1.015084  0.082306\n",
              "0.16    0.16       4  1.010537  0.070857\n",
              "0.17    0.17       3  1.006399  0.059603\n",
              "0.18    0.18       3  1.002989  0.050022\n",
              "0.19    0.19       2  1.000357  0.040557\n",
              "0.20    0.20       2  1.000022  0.033214\n",
              "0.21    0.21       2  0.999877  0.025496\n",
              "0.22    0.22       2  0.999923  0.017400\n",
              "0.23    0.23       2  1.000159  0.008929\n",
              "0.24    0.24       1  0.999923  0.003220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwnmtCDtqsg0"
      },
      "source": [
        "# 엘라스틱 넷 변수선택\n",
        "\n",
        "라쏘와 릿지의 제약식을 합친 회귀식으로써, 마찬가지로 제약식을 0으로 만드는 변수를 뺴고 남은 변수들로만 모델을 구성한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChPHX3LvHunK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1985dc13-0d63-41f4-e327-1f5886f70229"
      },
      "source": [
        "elastic_set=pd.DataFrame()\n",
        "for alpha_value in np.arange(0, 1.01, 0.01):\n",
        "  for ratio in np.arange(0.01, 1.01, 0.01 ):\n",
        "    elastic=ElasticNet(alpha= alpha_value, l1_ratio= ratio)\n",
        "    data2=train_set.copy()\n",
        "    data_elastic=test_set.copy()\n",
        "    elastic.fit(train_set.drop(['target1'],axis=1), train_set['target1'])\n",
        "    if np.sum(elastic.coef_ != 0) != 0:\n",
        "      elastic_predict = elastic.predict(test_set.drop(['target1'],axis=1))\n",
        "      elastic_rmse=np.sqrt(np.mean((test_set['target1'] - elastic_predict) ** 2 ))\n",
        "      elastic_a=alpha_value\n",
        "      elastic_r2=elastic.score(data2.drop(['target1'],axis=1), data2['target1'])\n",
        "      elastic_var=pd.DataFrame([np.sum(elastic.coef_ != 0)])\n",
        "      elastic_rmse = pd.DataFrame([elastic_rmse])\n",
        "      elastic_r2 =pd.DataFrame([elastic_r2])\n",
        "      elastic_a = pd.DataFrame([elastic_a])\n",
        "      elastic_l1=pd.DataFrame([ratio])\n",
        "      elastic_set0 = pd.concat([elastic_a,elastic_l1,elastic_var,elastic_rmse,elastic_r2],axis=1)\n",
        "      elastic_set=pd.concat([elastic_set,elastic_set0],axis=0)\n",
        "      elastic_set0=pd.DataFrame()\n",
        "      print('알파 값 :',str(elastic_a))\n",
        "      print('사용된 변수 개수 :', str(np.sum(elastic.coef_ != 0)))\n",
        "      print('RMSE :',str(elastic_rmse))\n",
        "      print('결정계수 :',str(elastic_r2))\n",
        "      print()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 :"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.0\n",
            "사용된 변수 개수 : 170\n",
            "RMSE :           0\n",
            "0  5.373803\n",
            "결정계수 :           0\n",
            "0  0.942649\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.01\n",
            "사용된 변수 개수 : 168\n",
            "RMSE :"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.950375604192301, tolerance: 0.017263549099428573\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 59\n",
            "RMSE :           0\n",
            "0  1.035803\n",
            "결정계수 :           0\n",
            "0  0.301886\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 50\n",
            "RMSE :           0\n",
            "0  1.031117\n",
            "결정계수 :           0\n",
            "0  0.270186\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 42\n",
            "RMSE :          0\n",
            "0  1.02693\n",
            "결정계수 :           0\n",
            "0  0.240064\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.023774\n",
            "결정계수 :          0\n",
            "0  0.21264\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 25\n",
            "RMSE :           0\n",
            "0  1.020797\n",
            "결정계수 :           0\n",
            "0  0.188441\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.018622\n",
            "결정계수 :           0\n",
            "0  0.166711\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 19\n",
            "RMSE :           0\n",
            "0  1.017011\n",
            "결정계수 :           0\n",
            "0  0.145824\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.015467\n",
            "결정계수 :           0\n",
            "0  0.126391\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.013751\n",
            "결정계수 :          0\n",
            "0  0.10834\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 13\n",
            "RMSE :           0\n",
            "0  1.011686\n",
            "결정계수 :           0\n",
            "0  0.090476\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 8\n",
            "RMSE :           0\n",
            "0  1.009664\n",
            "결정계수 :           0\n",
            "0  0.076232\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.009127\n",
            "결정계수 :           0\n",
            "0  0.066326\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.007938\n",
            "결정계수 :           0\n",
            "0  0.058198\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :          0\n",
            "0  1.00628\n",
            "결정계수 :           0\n",
            "0  0.051728\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004396\n",
            "결정계수 :           0\n",
            "0  0.045451\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002776\n",
            "결정계수 :          0\n",
            "0  0.03977\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001386\n",
            "결정계수 :           0\n",
            "0  0.034621\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000041\n",
            "결정계수 :           0\n",
            "0  0.029291\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999528\n",
            "결정계수 :           0\n",
            "0  0.024826\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999538\n",
            "결정계수 :           0\n",
            "0  0.020858\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999595\n",
            "결정계수 :          0\n",
            "0  0.01676\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999701\n",
            "결정계수 :           0\n",
            "0  0.012527\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999857\n",
            "결정계수 :           0\n",
            "0  0.008157\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  1.000005\n",
            "결정계수 :          0\n",
            "0  0.00393\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.78\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999753\n",
            "결정계수 :           0\n",
            "0  0.001652\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 141\n",
            "RMSE :           0\n",
            "0  1.069571\n",
            "결정계수 :           0\n",
            "0  0.517606\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 124\n",
            "RMSE :           0\n",
            "0  1.066039\n",
            "결정계수 :           0\n",
            "0  0.480771\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 108\n",
            "RMSE :           0\n",
            "0  1.060664\n",
            "결정계수 :           0\n",
            "0  0.442209\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 96\n",
            "RMSE :           0\n",
            "0  1.053056\n",
            "결정계수 :           0\n",
            "0  0.403771\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 81\n",
            "RMSE :           0\n",
            "0  1.045684\n",
            "결정계수 :          0\n",
            "0  0.36688\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 71\n",
            "RMSE :           0\n",
            "0  1.039902\n",
            "결정계수 :           0\n",
            "0  0.331602\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 58\n",
            "RMSE :          0\n",
            "0  1.03509\n",
            "결정계수 :           0\n",
            "0  0.297757\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 50\n",
            "RMSE :           0\n",
            "0  1.030307\n",
            "결정계수 :           0\n",
            "0  0.265893\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 41\n",
            "RMSE :           0\n",
            "0  1.026347\n",
            "결정계수 :           0\n",
            "0  0.235823\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 35\n",
            "RMSE :           0\n",
            "0  1.023154\n",
            "결정계수 :           0\n",
            "0  0.208231\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.020174\n",
            "결정계수 :           0\n",
            "0  0.184526\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 23\n",
            "RMSE :           0\n",
            "0  1.018143\n",
            "결정계수 :           0\n",
            "0  0.162541\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 19\n",
            "RMSE :           0\n",
            "0  1.016576\n",
            "결정계수 :           0\n",
            "0  0.141805\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :          0\n",
            "0  1.01506\n",
            "결정계수 :           0\n",
            "0  0.122333\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.013209\n",
            "결정계수 :           0\n",
            "0  0.104393\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 12\n",
            "RMSE :           0\n",
            "0  1.011045\n",
            "결정계수 :           0\n",
            "0  0.086755\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 8\n",
            "RMSE :           0\n",
            "0  1.009244\n",
            "결정계수 :           0\n",
            "0  0.073377\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.008776\n",
            "결정계수 :           0\n",
            "0  0.064109\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.007544\n",
            "결정계수 :           0\n",
            "0  0.056242\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005742\n",
            "결정계수 :           0\n",
            "0  0.049886\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003861\n",
            "결정계수 :           0\n",
            "0  0.043496\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002355\n",
            "결정계수 :           0\n",
            "0  0.038136\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000972\n",
            "결정계수 :           0\n",
            "0  0.032893\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  0.999633\n",
            "결정계수 :           0\n",
            "0  0.027467\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999522\n",
            "결정계수 :           0\n",
            "0  0.023436\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999549\n",
            "결정계수 :           0\n",
            "0  0.019395\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999624\n",
            "결정계수 :           0\n",
            "0  0.015221\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99975\n",
            "결정계수 :           0\n",
            "0  0.010909\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999926\n",
            "결정계수 :           0\n",
            "0  0.006457\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999903\n",
            "결정계수 :           0\n",
            "0  0.003044\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.79\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999659\n",
            "결정계수 :           0\n",
            "0  0.000723\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 141\n",
            "RMSE :           0\n",
            "0  1.068698\n",
            "결정계수 :           0\n",
            "0  0.515236\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 124\n",
            "RMSE :           0\n",
            "0  1.065166\n",
            "결정계수 :           0\n",
            "0  0.478009\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 107\n",
            "RMSE :           0\n",
            "0  1.059719\n",
            "결정계수 :           0\n",
            "0  0.439076\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 95\n",
            "RMSE :           0\n",
            "0  1.052046\n",
            "결정계수 :           0\n",
            "0  0.400307\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 80\n",
            "RMSE :           0\n",
            "0  1.044919\n",
            "결정계수 :           0\n",
            "0  0.363164\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 70\n",
            "RMSE :           0\n",
            "0  1.039091\n",
            "결정계수 :          0\n",
            "0  0.32767\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 58\n",
            "RMSE :           0\n",
            "0  1.034373\n",
            "결정계수 :           0\n",
            "0  0.293689\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 50\n",
            "RMSE :          0\n",
            "0  1.02952\n",
            "결정계수 :          0\n",
            "0  0.26161\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 41\n",
            "RMSE :           0\n",
            "0  1.025784\n",
            "결정계수 :           0\n",
            "0  0.231612\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 34\n",
            "RMSE :           0\n",
            "0  1.022607\n",
            "결정계수 :           0\n",
            "0  0.204044\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.019656\n",
            "결정계수 :           0\n",
            "0  0.180673\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 22\n",
            "RMSE :           0\n",
            "0  1.017686\n",
            "결정계수 :           0\n",
            "0  0.158473\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 18\n",
            "RMSE :           0\n",
            "0  1.016137\n",
            "결정계수 :           0\n",
            "0  0.137841\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.014625\n",
            "결정계수 :           0\n",
            "0  0.118514\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.012684\n",
            "결정계수 :           0\n",
            "0  0.100459\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 12\n",
            "RMSE :           0\n",
            "0  1.010422\n",
            "결정계수 :          0\n",
            "0  0.08305\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.009125\n",
            "결정계수 :           0\n",
            "0  0.070946\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.008435\n",
            "결정계수 :           0\n",
            "0  0.061895\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.007145\n",
            "결정계수 :           0\n",
            "0  0.054312\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005216\n",
            "결정계수 :           0\n",
            "0  0.048045\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.003366\n",
            "결정계수 :           0\n",
            "0  0.041655\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001945\n",
            "결정계수 :           0\n",
            "0  0.036503\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000567\n",
            "결정계수 :           0\n",
            "0  0.031167\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999526\n",
            "결정계수 :           0\n",
            "0  0.026028\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999522\n",
            "결정계수 :           0\n",
            "0  0.022047\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999566\n",
            "결정계수 :           0\n",
            "0  0.017933\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99966\n",
            "결정계수 :           0\n",
            "0  0.013683\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999804\n",
            "결정계수 :           0\n",
            "0  0.009293\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  1.000001\n",
            "결정계수 :           0\n",
            "0  0.004759\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.8\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999807\n",
            "결정계수 :           0\n",
            "0  0.002158\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 141\n",
            "RMSE :           0\n",
            "0  1.067843\n",
            "결정계수 :           0\n",
            "0  0.512886\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 124\n",
            "RMSE :           0\n",
            "0  1.064313\n",
            "결정계수 :           0\n",
            "0  0.475266\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 107\n",
            "RMSE :           0\n",
            "0  1.058781\n",
            "결정계수 :           0\n",
            "0  0.435978\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 94\n",
            "RMSE :           0\n",
            "0  1.051051\n",
            "결정계수 :           0\n",
            "0  0.396867\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 79\n",
            "RMSE :          0\n",
            "0  1.04416\n",
            "결정계수 :           0\n",
            "0  0.359471\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 70\n",
            "RMSE :           0\n",
            "0  1.038302\n",
            "결정계수 :          0\n",
            "0  0.32375\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 58\n",
            "RMSE :           0\n",
            "0  1.033676\n",
            "결정계수 :           0\n",
            "0  0.289632\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 49\n",
            "RMSE :           0\n",
            "0  1.028754\n",
            "결정계수 :           0\n",
            "0  0.257348\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 40\n",
            "RMSE :           0\n",
            "0  1.025191\n",
            "결정계수 :           0\n",
            "0  0.227473\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 32\n",
            "RMSE :           0\n",
            "0  1.022087\n",
            "결정계수 :           0\n",
            "0  0.199944\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.019158\n",
            "결정계수 :          0\n",
            "0  0.17683\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 22\n",
            "RMSE :           0\n",
            "0  1.017286\n",
            "결정계수 :           0\n",
            "0  0.154488\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.015708\n",
            "결정계수 :           0\n",
            "0  0.133929\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.014205\n",
            "결정계수 :           0\n",
            "0  0.114708\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.012176\n",
            "결정계수 :           0\n",
            "0  0.096538\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 10\n",
            "RMSE :       0\n",
            "0  1.01\n",
            "결정계수 :           0\n",
            "0  0.079553\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.009023\n",
            "결정계수 :           0\n",
            "0  0.068532\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.008104\n",
            "결정계수 :           0\n",
            "0  0.059684\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.006627\n",
            "결정계수 :           0\n",
            "0  0.052581\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :         0\n",
            "0  1.0047\n",
            "결정계수 :           0\n",
            "0  0.046207\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :          0\n",
            "0  1.00296\n",
            "결정계수 :           0\n",
            "0  0.040113\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001544\n",
            "결정계수 :           0\n",
            "0  0.034871\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000173\n",
            "결정계수 :           0\n",
            "0  0.029443\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999515\n",
            "결정계수 :          0\n",
            "0  0.02471\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999528\n",
            "결정계수 :           0\n",
            "0  0.020659\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999589\n",
            "결정계수 :           0\n",
            "0  0.016473\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999701\n",
            "결정계수 :           0\n",
            "0  0.012146\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999865\n",
            "결정계수 :           0\n",
            "0  0.007677\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999967\n",
            "결정계수 :           0\n",
            "0  0.003607\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.81\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999714\n",
            "결정계수 :           0\n",
            "0  0.001273\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 141\n",
            "RMSE :           0\n",
            "0  1.067008\n",
            "결정계수 :           0\n",
            "0  0.510554\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 124\n",
            "RMSE :          0\n",
            "0  1.06348\n",
            "결정계수 :           0\n",
            "0  0.472541\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 107\n",
            "RMSE :           0\n",
            "0  1.057837\n",
            "결정계수 :           0\n",
            "0  0.432888\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 91\n",
            "RMSE :          0\n",
            "0  1.05007\n",
            "결정계수 :           0\n",
            "0  0.393459\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 79\n",
            "RMSE :           0\n",
            "0  1.043301\n",
            "결정계수 :           0\n",
            "0  0.355838\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 68\n",
            "RMSE :           0\n",
            "0  1.037523\n",
            "결정계수 :           0\n",
            "0  0.319878\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 56\n",
            "RMSE :           0\n",
            "0  1.032986\n",
            "결정계수 :           0\n",
            "0  0.285599\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 48\n",
            "RMSE :           0\n",
            "0  1.028043\n",
            "결정계수 :           0\n",
            "0  0.253199\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.024546\n",
            "결정계수 :           0\n",
            "0  0.223442\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 30\n",
            "RMSE :           0\n",
            "0  1.021475\n",
            "결정계수 :           0\n",
            "0  0.195973\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.018678\n",
            "결정계수 :           0\n",
            "0  0.172997\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.016878\n",
            "결정계수 :           0\n",
            "0  0.150673\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.015307\n",
            "결정계수 :           0\n",
            "0  0.130131\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.013801\n",
            "결정계수 :           0\n",
            "0  0.110915\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.011684\n",
            "결정계수 :           0\n",
            "0  0.092631\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 9\n",
            "RMSE :           0\n",
            "0  1.009552\n",
            "결정계수 :           0\n",
            "0  0.076633\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.008929\n",
            "결정계수 :           0\n",
            "0  0.066123\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.007764\n",
            "결정계수 :         0\n",
            "0  0.0576\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.006119\n",
            "결정계수 :           0\n",
            "0  0.050853\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004194\n",
            "결정계수 :           0\n",
            "0  0.044371\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002563\n",
            "결정계수 :           0\n",
            "0  0.038573\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001153\n",
            "결정계수 :           0\n",
            "0  0.033242\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  0.999789\n",
            "결정계수 :          0\n",
            "0  0.02772\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99951\n",
            "결정계수 :           0\n",
            "0  0.023394\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999539\n",
            "결정계수 :           0\n",
            "0  0.019273\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999618\n",
            "결정계수 :           0\n",
            "0  0.015013\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999748\n",
            "결정계수 :           0\n",
            "0  0.010611\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999932\n",
            "결정계수 :           0\n",
            "0  0.006062\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999872\n",
            "결정계수 :           0\n",
            "0  0.002764\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.82\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999627\n",
            "결정계수 :           0\n",
            "0  0.000387\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 140\n",
            "RMSE :           0\n",
            "0  1.066192\n",
            "결정계수 :           0\n",
            "0  0.508244\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 124\n",
            "RMSE :           0\n",
            "0  1.062667\n",
            "결정계수 :           0\n",
            "0  0.469834\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 106\n",
            "RMSE :           0\n",
            "0  1.056942\n",
            "결정계수 :           0\n",
            "0  0.429828\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 92\n",
            "RMSE :           0\n",
            "0  1.049101\n",
            "결정계수 :           0\n",
            "0  0.390082\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 78\n",
            "RMSE :           0\n",
            "0  1.042469\n",
            "결정계수 :           0\n",
            "0  0.352226\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 68\n",
            "RMSE :           0\n",
            "0  1.036742\n",
            "결정계수 :           0\n",
            "0  0.316044\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 55\n",
            "RMSE :           0\n",
            "0  1.032285\n",
            "결정계수 :           0\n",
            "0  0.281592\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 48\n",
            "RMSE :           0\n",
            "0  1.027385\n",
            "결정계수 :          0\n",
            "0  0.24908\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.023912\n",
            "결정계수 :           0\n",
            "0  0.219429\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 29\n",
            "RMSE :           0\n",
            "0  1.020846\n",
            "결정계수 :          0\n",
            "0  0.19207\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.018216\n",
            "결정계수 :           0\n",
            "0  0.169174\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.016484\n",
            "결정계수 :          0\n",
            "0  0.14688\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.014921\n",
            "결정계수 :           0\n",
            "0  0.126345\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.013314\n",
            "결정계수 :           0\n",
            "0  0.107263\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 13\n",
            "RMSE :           0\n",
            "0  1.011206\n",
            "결정계수 :           0\n",
            "0  0.088747\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 8\n",
            "RMSE :          0\n",
            "0  1.00916\n",
            "결정계수 :          0\n",
            "0  0.07399\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.008642\n",
            "결정계수 :           0\n",
            "0  0.064004\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :         0\n",
            "0  1.0074\n",
            "결정계수 :           0\n",
            "0  0.055771\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005621\n",
            "결정계수 :           0\n",
            "0  0.049127\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003699\n",
            "결정계수 :           0\n",
            "0  0.042538\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002175\n",
            "결정계수 :           0\n",
            "0  0.037035\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000771\n",
            "결정계수 :           0\n",
            "0  0.031614\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999515\n",
            "결정계수 :           0\n",
            "0  0.026133\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99951\n",
            "결정계수 :          0\n",
            "0  0.02208\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999555\n",
            "결정계수 :           0\n",
            "0  0.017888\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999652\n",
            "결정계수 :           0\n",
            "0  0.013555\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999801\n",
            "결정계수 :           0\n",
            "0  0.009077\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  1.000005\n",
            "결정계수 :           0\n",
            "0  0.004449\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.83\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999781\n",
            "결정계수 :          0\n",
            "0  0.00192\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 140\n",
            "RMSE :           0\n",
            "0  1.065394\n",
            "결정계수 :           0\n",
            "0  0.505954\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 123\n",
            "RMSE :           0\n",
            "0  1.061874\n",
            "결정계수 :           0\n",
            "0  0.467156\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 106\n",
            "RMSE :          0\n",
            "0  1.05607\n",
            "결정계수 :           0\n",
            "0  0.426787\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 92\n",
            "RMSE :           0\n",
            "0  1.048146\n",
            "결정계수 :           0\n",
            "0  0.386718\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 77\n",
            "RMSE :           0\n",
            "0  1.041674\n",
            "결정계수 :           0\n",
            "0  0.348665\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 67\n",
            "RMSE :           0\n",
            "0  1.036037\n",
            "결정계수 :           0\n",
            "0  0.312242\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 55\n",
            "RMSE :           0\n",
            "0  1.031596\n",
            "결정계수 :           0\n",
            "0  0.277607\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 48\n",
            "RMSE :           0\n",
            "0  1.026748\n",
            "결정계수 :           0\n",
            "0  0.244971\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.023298\n",
            "결정계수 :           0\n",
            "0  0.215423\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 27\n",
            "RMSE :          0\n",
            "0  1.02027\n",
            "결정계수 :           0\n",
            "0  0.188302\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.017772\n",
            "결정계수 :           0\n",
            "0  0.165361\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.016105\n",
            "결정계수 :           0\n",
            "0  0.143097\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.014549\n",
            "결정계수 :           0\n",
            "0  0.122573\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.012819\n",
            "결정계수 :           0\n",
            "0  0.103655\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 12\n",
            "RMSE :           0\n",
            "0  1.010639\n",
            "결정계수 :          0\n",
            "0  0.08526\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.008858\n",
            "결정계수 :           0\n",
            "0  0.071469\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.008324\n",
            "결정계수 :           0\n",
            "0  0.061944\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.007045\n",
            "결정계수 :           0\n",
            "0  0.053944\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005133\n",
            "결정계수 :           0\n",
            "0  0.047403\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.003242\n",
            "결정계수 :           0\n",
            "0  0.040816\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001797\n",
            "결정계수 :           0\n",
            "0  0.035499\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000398\n",
            "결정계수 :           0\n",
            "0  0.029989\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999505\n",
            "결정계수 :           0\n",
            "0  0.024888\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999515\n",
            "결정계수 :           0\n",
            "0  0.020767\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999577\n",
            "결정계수 :           0\n",
            "0  0.016505\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999691\n",
            "결정계수 :           0\n",
            "0  0.012099\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999859\n",
            "결정계수 :           0\n",
            "0  0.007544\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :          0\n",
            "0  0.99995\n",
            "결정계수 :           0\n",
            "0  0.003461\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.84\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999695\n",
            "결정계수 :           0\n",
            "0  0.001078\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 140\n",
            "RMSE :           0\n",
            "0  1.064614\n",
            "결정계수 :          0\n",
            "0  0.50368\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 123\n",
            "RMSE :         0\n",
            "0  1.0611\n",
            "결정계수 :           0\n",
            "0  0.464503\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 105\n",
            "RMSE :           0\n",
            "0  1.055214\n",
            "결정계수 :           0\n",
            "0  0.423775\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 91\n",
            "RMSE :           0\n",
            "0  1.047204\n",
            "결정계수 :           0\n",
            "0  0.383371\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 76\n",
            "RMSE :           0\n",
            "0  1.040889\n",
            "결정계수 :          0\n",
            "0  0.34515\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 66\n",
            "RMSE :           0\n",
            "0  1.035378\n",
            "결정계수 :           0\n",
            "0  0.308465\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 53\n",
            "RMSE :           0\n",
            "0  1.030918\n",
            "결정계수 :           0\n",
            "0  0.273711\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 47\n",
            "RMSE :           0\n",
            "0  1.026104\n",
            "결정계수 :           0\n",
            "0  0.240916\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.022701\n",
            "결정계수 :           0\n",
            "0  0.211427\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 27\n",
            "RMSE :           0\n",
            "0  1.019702\n",
            "결정계수 :           0\n",
            "0  0.184636\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.017344\n",
            "결정계수 :           0\n",
            "0  0.161559\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 20\n",
            "RMSE :           0\n",
            "0  1.015711\n",
            "결정계수 :           0\n",
            "0  0.139385\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 16\n",
            "RMSE :           0\n",
            "0  1.014192\n",
            "결정계수 :           0\n",
            "0  0.118872\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.012339\n",
            "결정계수 :          0\n",
            "0  0.10006\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 12\n",
            "RMSE :           0\n",
            "0  1.010073\n",
            "결정계수 :           0\n",
            "0  0.081863\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.008759\n",
            "결정계수 :           0\n",
            "0  0.069232\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.008015\n",
            "결정계수 :           0\n",
            "0  0.059887\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.006624\n",
            "결정계수 :           0\n",
            "0  0.052234\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004654\n",
            "결정계수 :           0\n",
            "0  0.045683\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002866\n",
            "결정계수 :           0\n",
            "0  0.039368\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001426\n",
            "결정계수 :           0\n",
            "0  0.033966\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000034\n",
            "결정계수 :           0\n",
            "0  0.028365\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999499\n",
            "결정계수 :           0\n",
            "0  0.023645\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999525\n",
            "결정계수 :           0\n",
            "0  0.019456\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999604\n",
            "결정계수 :           0\n",
            "0  0.015124\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999736\n",
            "결정계수 :           0\n",
            "0  0.010644\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999923\n",
            "결정계수 :           0\n",
            "0  0.006013\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999861\n",
            "결정계수 :          0\n",
            "0  0.00266\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.85\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999612\n",
            "결정계수 :           0\n",
            "0  0.000235\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 140\n",
            "RMSE :           0\n",
            "0  1.063849\n",
            "결정계수 :           0\n",
            "0  0.501424\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 123\n",
            "RMSE :           0\n",
            "0  1.060347\n",
            "결정계수 :           0\n",
            "0  0.461868\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 105\n",
            "RMSE :           0\n",
            "0  1.054366\n",
            "결정계수 :           0\n",
            "0  0.420809\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 90\n",
            "RMSE :           0\n",
            "0  1.046295\n",
            "결정계수 :           0\n",
            "0  0.380048\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 75\n",
            "RMSE :           0\n",
            "0  1.040115\n",
            "결정계수 :           0\n",
            "0  0.341656\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 65\n",
            "RMSE :           0\n",
            "0  1.034737\n",
            "결정계수 :           0\n",
            "0  0.304707\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 53\n",
            "RMSE :           0\n",
            "0  1.030246\n",
            "결정계수 :           0\n",
            "0  0.269856\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 46\n",
            "RMSE :           0\n",
            "0  1.025452\n",
            "결정계수 :           0\n",
            "0  0.236928\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.022121\n",
            "결정계수 :           0\n",
            "0  0.207439\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 25\n",
            "RMSE :           0\n",
            "0  1.019143\n",
            "결정계수 :           0\n",
            "0  0.181087\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 23\n",
            "RMSE :           0\n",
            "0  1.016929\n",
            "결정계수 :           0\n",
            "0  0.157806\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 19\n",
            "RMSE :           0\n",
            "0  1.015338\n",
            "결정계수 :           0\n",
            "0  0.135756\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.013821\n",
            "결정계수 :           0\n",
            "0  0.115366\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.011874\n",
            "결정계수 :           0\n",
            "0  0.096478\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 11\n",
            "RMSE :           0\n",
            "0  1.009639\n",
            "결정계수 :           0\n",
            "0  0.078597\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.008667\n",
            "결정계수 :           0\n",
            "0  0.067001\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.007714\n",
            "결정계수 :           0\n",
            "0  0.057835\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.006152\n",
            "결정계수 :           0\n",
            "0  0.050619\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004184\n",
            "결정계수 :           0\n",
            "0  0.043965\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002499\n",
            "결정계수 :           0\n",
            "0  0.037923\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001065\n",
            "결정계수 :           0\n",
            "0  0.032434\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  0.999679\n",
            "결정계수 :           0\n",
            "0  0.026744\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999498\n",
            "결정계수 :           0\n",
            "0  0.022404\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99954\n",
            "결정계수 :           0\n",
            "0  0.018147\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999635\n",
            "결정계수 :           0\n",
            "0  0.013745\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999785\n",
            "결정계수 :           0\n",
            "0  0.009191\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999992\n",
            "결정계수 :           0\n",
            "0  0.004483\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.86\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999775\n",
            "결정계수 :           0\n",
            "0  0.001859\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 139\n",
            "RMSE :           0\n",
            "0  1.063087\n",
            "결정계수 :           0\n",
            "0  0.499191\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 123\n",
            "RMSE :           0\n",
            "0  1.059606\n",
            "결정계수 :           0\n",
            "0  0.459249\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 104\n",
            "RMSE :           0\n",
            "0  1.053552\n",
            "결정계수 :           0\n",
            "0  0.417863\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 89\n",
            "RMSE :           0\n",
            "0  1.045431\n",
            "결정계수 :           0\n",
            "0  0.376749\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 74\n",
            "RMSE :           0\n",
            "0  1.039369\n",
            "결정계수 :           0\n",
            "0  0.338248\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 64\n",
            "RMSE :           0\n",
            "0  1.034143\n",
            "결정계수 :           0\n",
            "0  0.301038\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 52\n",
            "RMSE :           0\n",
            "0  1.029532\n",
            "결정계수 :           0\n",
            "0  0.266085\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 43\n",
            "RMSE :           0\n",
            "0  1.024875\n",
            "결정계수 :           0\n",
            "0  0.233104\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 38\n",
            "RMSE :           0\n",
            "0  1.021564\n",
            "결정계수 :           0\n",
            "0  0.203483\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 25\n",
            "RMSE :           0\n",
            "0  1.018598\n",
            "결정계수 :           0\n",
            "0  0.177585\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 23\n",
            "RMSE :           0\n",
            "0  1.016521\n",
            "결정계수 :           0\n",
            "0  0.154133\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 18\n",
            "RMSE :           0\n",
            "0  1.014966\n",
            "결정계수 :           0\n",
            "0  0.132167\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.013447\n",
            "결정계수 :           0\n",
            "0  0.111912\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.011423\n",
            "결정계수 :           0\n",
            "0  0.092911\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 9\n",
            "RMSE :           0\n",
            "0  1.009234\n",
            "결정계수 :           0\n",
            "0  0.075716\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.008582\n",
            "결정계수 :           0\n",
            "0  0.064775\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.007392\n",
            "결정계수 :           0\n",
            "0  0.055998\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005689\n",
            "결정계수 :           0\n",
            "0  0.049008\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003724\n",
            "결정계수 :           0\n",
            "0  0.042251\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :          0\n",
            "0  1.00214\n",
            "결정계수 :           0\n",
            "0  0.036481\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000711\n",
            "결정계수 :           0\n",
            "0  0.030906\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999496\n",
            "결정계수 :           0\n",
            "0  0.025343\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999501\n",
            "결정계수 :           0\n",
            "0  0.021164\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999559\n",
            "결정계수 :           0\n",
            "0  0.016841\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999672\n",
            "결정계수 :           0\n",
            "0  0.012367\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99984\n",
            "결정계수 :          0\n",
            "0  0.00774\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999953\n",
            "결정계수 :           0\n",
            "0  0.003486\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.87\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999693\n",
            "결정계수 :           0\n",
            "0  0.001059\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 139\n",
            "RMSE :           0\n",
            "0  1.062337\n",
            "결정계수 :           0\n",
            "0  0.496976\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 123\n",
            "RMSE :           0\n",
            "0  1.058882\n",
            "결정계수 :           0\n",
            "0  0.456647\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 104\n",
            "RMSE :           0\n",
            "0  1.052774\n",
            "결정계수 :           0\n",
            "0  0.414936\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 86\n",
            "RMSE :          0\n",
            "0  1.04464\n",
            "결정계수 :           0\n",
            "0  0.373512\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 74\n",
            "RMSE :           0\n",
            "0  1.038654\n",
            "결정계수 :           0\n",
            "0  0.334867\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 62\n",
            "RMSE :           0\n",
            "0  1.033507\n",
            "결정계수 :           0\n",
            "0  0.297416\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 52\n",
            "RMSE :           0\n",
            "0  1.028819\n",
            "결정계수 :           0\n",
            "0  0.262346\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 41\n",
            "RMSE :           0\n",
            "0  1.024315\n",
            "결정계수 :           0\n",
            "0  0.229372\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 36\n",
            "RMSE :           0\n",
            "0  1.021037\n",
            "결정계수 :           0\n",
            "0  0.199648\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.018115\n",
            "결정계수 :           0\n",
            "0  0.174121\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 22\n",
            "RMSE :           0\n",
            "0  1.016157\n",
            "결정계수 :           0\n",
            "0  0.150525\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.014594\n",
            "결정계수 :           0\n",
            "0  0.128629\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.013086\n",
            "결정계수 :          0\n",
            "0  0.10847\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.010986\n",
            "결정계수 :           0\n",
            "0  0.089357\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 8\n",
            "RMSE :           0\n",
            "0  1.008872\n",
            "결정계수 :           0\n",
            "0  0.073236\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.008333\n",
            "결정계수 :           0\n",
            "0  0.062796\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.007061\n",
            "결정계수 :           0\n",
            "0  0.054297\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005235\n",
            "결정계수 :           0\n",
            "0  0.047399\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003272\n",
            "결정계수 :          0\n",
            "0  0.04054\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001789\n",
            "결정계수 :          0\n",
            "0  0.03504\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000366\n",
            "결정계수 :          0\n",
            "0  0.02938\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999488\n",
            "결정계수 :           0\n",
            "0  0.024171\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999509\n",
            "결정계수 :           0\n",
            "0  0.019927\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999583\n",
            "결정계수 :           0\n",
            "0  0.015536\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999713\n",
            "결정계수 :           0\n",
            "0  0.010992\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999899\n",
            "결정계수 :           0\n",
            "0  0.006291\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999868\n",
            "결정계수 :           0\n",
            "0  0.002726\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.88\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999614\n",
            "결정계수 :          0\n",
            "0  0.00026\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 139\n",
            "RMSE :           0\n",
            "0  1.061603\n",
            "결정계수 :           0\n",
            "0  0.494777\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 123\n",
            "RMSE :           0\n",
            "0  1.058174\n",
            "결정계수 :           0\n",
            "0  0.454061\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 104\n",
            "RMSE :           0\n",
            "0  1.052014\n",
            "결정계수 :           0\n",
            "0  0.412026\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 84\n",
            "RMSE :           0\n",
            "0  1.043949\n",
            "결정계수 :           0\n",
            "0  0.370381\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 74\n",
            "RMSE :           0\n",
            "0  1.037955\n",
            "결정계수 :           0\n",
            "0  0.331497\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 61\n",
            "RMSE :           0\n",
            "0  1.032896\n",
            "결정계수 :          0\n",
            "0  0.29383\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 51\n",
            "RMSE :           0\n",
            "0  1.028127\n",
            "결정계수 :           0\n",
            "0  0.258618\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 41\n",
            "RMSE :           0\n",
            "0  1.023838\n",
            "결정계수 :           0\n",
            "0  0.225686\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 34\n",
            "RMSE :           0\n",
            "0  1.020575\n",
            "결정계수 :           0\n",
            "0  0.195938\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :          0\n",
            "0  1.01769\n",
            "결정계수 :           0\n",
            "0  0.170695\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.015814\n",
            "결정계수 :          0\n",
            "0  0.14701\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.014247\n",
            "결정계수 :           0\n",
            "0  0.125207\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.012717\n",
            "결정계수 :           0\n",
            "0  0.105068\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 13\n",
            "RMSE :           0\n",
            "0  1.010552\n",
            "결정계수 :           0\n",
            "0  0.085851\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 8\n",
            "RMSE :           0\n",
            "0  1.008526\n",
            "결정계수 :           0\n",
            "0  0.070818\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.008042\n",
            "결정계수 :           0\n",
            "0  0.060889\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.006737\n",
            "결정계수 :           0\n",
            "0  0.052598\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004789\n",
            "결정계수 :           0\n",
            "0  0.045794\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002912\n",
            "결정계수 :           0\n",
            "0  0.039143\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001445\n",
            "결정계수 :           0\n",
            "0  0.033603\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000029\n",
            "결정계수 :           0\n",
            "0  0.027856\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999485\n",
            "결정계수 :           0\n",
            "0  0.023001\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999521\n",
            "결정계수 :           0\n",
            "0  0.018693\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999611\n",
            "결정계수 :           0\n",
            "0  0.014233\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999758\n",
            "결정계수 :           0\n",
            "0  0.009619\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999963\n",
            "결정계수 :           0\n",
            "0  0.004845\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.89\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999786\n",
            "결정계수 :           0\n",
            "0  0.001967\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 139\n",
            "RMSE :           0\n",
            "0  1.060883\n",
            "결정계수 :           0\n",
            "0  0.492594\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 123\n",
            "RMSE :           0\n",
            "0  1.057481\n",
            "결정계수 :           0\n",
            "0  0.451491\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 104\n",
            "RMSE :          0\n",
            "0  1.05127\n",
            "결정계수 :          0\n",
            "0  0.40913\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 84\n",
            "RMSE :          0\n",
            "0  1.04329\n",
            "결정계수 :           0\n",
            "0  0.367299\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 74\n",
            "RMSE :           0\n",
            "0  1.037272\n",
            "결정계수 :           0\n",
            "0  0.328138\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 61\n",
            "RMSE :           0\n",
            "0  1.032319\n",
            "결정계수 :           0\n",
            "0  0.290267\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 51\n",
            "RMSE :           0\n",
            "0  1.027464\n",
            "결정계수 :           0\n",
            "0  0.254916\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 41\n",
            "RMSE :           0\n",
            "0  1.023376\n",
            "결정계수 :           0\n",
            "0  0.222011\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 33\n",
            "RMSE :           0\n",
            "0  1.020163\n",
            "결정계수 :           0\n",
            "0  0.192293\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.017281\n",
            "결정계수 :          0\n",
            "0  0.16728\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.015468\n",
            "결정계수 :           0\n",
            "0  0.143603\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.013912\n",
            "결정계수 :           0\n",
            "0  0.121798\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.012274\n",
            "결정계수 :           0\n",
            "0  0.101797\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 12\n",
            "RMSE :          0\n",
            "0  1.01005\n",
            "결정계수 :           0\n",
            "0  0.082653\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.008433\n",
            "결정계수 :           0\n",
            "0  0.068758\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.007759\n",
            "결정계수 :           0\n",
            "0  0.058987\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.006366\n",
            "결정계수 :           0\n",
            "0  0.050988\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004352\n",
            "결정계수 :           0\n",
            "0  0.044192\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002571\n",
            "결정계수 :          0\n",
            "0  0.03779\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001109\n",
            "결정계수 :           0\n",
            "0  0.032168\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  0.999699\n",
            "결정계수 :           0\n",
            "0  0.026335\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999486\n",
            "결정계수 :           0\n",
            "0  0.021834\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999537\n",
            "결정계수 :          0\n",
            "0  0.01746\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999644\n",
            "결정계수 :           0\n",
            "0  0.012933\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999808\n",
            "결정계수 :           0\n",
            "0  0.008248\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999974\n",
            "결정계수 :           0\n",
            "0  0.003671\n",
            "\n",
            "알파 값 :      0\n",
            "0  0.9\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999708\n",
            "결정계수 :           0\n",
            "0  0.001209\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 137\n",
            "RMSE :           0\n",
            "0  1.060169\n",
            "결정계수 :           0\n",
            "0  0.490432\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 123\n",
            "RMSE :           0\n",
            "0  1.056802\n",
            "결정계수 :           0\n",
            "0  0.448938\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 103\n",
            "RMSE :           0\n",
            "0  1.050539\n",
            "결정계수 :           0\n",
            "0  0.406251\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 84\n",
            "RMSE :           0\n",
            "0  1.042646\n",
            "결정계수 :           0\n",
            "0  0.364231\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 74\n",
            "RMSE :           0\n",
            "0  1.036605\n",
            "결정계수 :           0\n",
            "0  0.324791\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 60\n",
            "RMSE :           0\n",
            "0  1.031757\n",
            "결정계수 :           0\n",
            "0  0.286718\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 50\n",
            "RMSE :           0\n",
            "0  1.026818\n",
            "결정계수 :           0\n",
            "0  0.251226\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.022885\n",
            "결정계수 :           0\n",
            "0  0.218403\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 32\n",
            "RMSE :           0\n",
            "0  1.019719\n",
            "결정계수 :          0\n",
            "0  0.18874\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.016885\n",
            "결정계수 :           0\n",
            "0  0.163876\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.015135\n",
            "결정계수 :           0\n",
            "0  0.140207\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.013589\n",
            "결정계수 :           0\n",
            "0  0.118402\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.011843\n",
            "결정계수 :           0\n",
            "0  0.098539\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 12\n",
            "RMSE :           0\n",
            "0  1.009544\n",
            "결정계수 :           0\n",
            "0  0.079562\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.008347\n",
            "결정계수 :           0\n",
            "0  0.066703\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.007483\n",
            "결정계수 :          0\n",
            "0  0.05709\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005934\n",
            "결정계수 :           0\n",
            "0  0.049487\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003922\n",
            "결정계수 :           0\n",
            "0  0.042594\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002236\n",
            "결정계수 :           0\n",
            "0  0.036441\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000781\n",
            "결정계수 :           0\n",
            "0  0.030737\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99948\n",
            "결정계수 :           0\n",
            "0  0.024954\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999491\n",
            "결정계수 :           0\n",
            "0  0.020669\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999557\n",
            "결정계수 :          0\n",
            "0  0.01623\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999681\n",
            "결정계수 :           0\n",
            "0  0.011635\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999863\n",
            "결정계수 :           0\n",
            "0  0.006879\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999893\n",
            "결정계수 :           0\n",
            "0  0.002951\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.91\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999633\n",
            "결정계수 :           0\n",
            "0  0.000451\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 138\n",
            "RMSE :           0\n",
            "0  1.059449\n",
            "결정계수 :           0\n",
            "0  0.488294\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 122\n",
            "RMSE :           0\n",
            "0  1.056135\n",
            "결정계수 :           0\n",
            "0  0.446403\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 103\n",
            "RMSE :           0\n",
            "0  1.049811\n",
            "결정계수 :           0\n",
            "0  0.403395\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 84\n",
            "RMSE :           0\n",
            "0  1.042017\n",
            "결정계수 :           0\n",
            "0  0.361175\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 74\n",
            "RMSE :           0\n",
            "0  1.035953\n",
            "결정계수 :           0\n",
            "0  0.321456\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 59\n",
            "RMSE :           0\n",
            "0  1.031182\n",
            "결정계수 :           0\n",
            "0  0.283258\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 50\n",
            "RMSE :           0\n",
            "0  1.026198\n",
            "결정계수 :           0\n",
            "0  0.247555\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.022343\n",
            "결정계수 :           0\n",
            "0  0.214891\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 31\n",
            "RMSE :           0\n",
            "0  1.019204\n",
            "결정계수 :          0\n",
            "0  0.18526\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.016503\n",
            "결정계수 :           0\n",
            "0  0.160483\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.014814\n",
            "결정계수 :           0\n",
            "0  0.136822\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 16\n",
            "RMSE :           0\n",
            "0  1.013278\n",
            "결정계수 :           0\n",
            "0  0.115062\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.011424\n",
            "결정계수 :           0\n",
            "0  0.095294\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 11\n",
            "RMSE :           0\n",
            "0  1.009168\n",
            "결정계수 :           0\n",
            "0  0.076604\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.008266\n",
            "결정계수 :           0\n",
            "0  0.064655\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.007201\n",
            "결정계수 :           0\n",
            "0  0.055296\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :          0\n",
            "0  1.00551\n",
            "결정계수 :           0\n",
            "0  0.047991\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003501\n",
            "결정계수 :           0\n",
            "0  0.040999\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001909\n",
            "결정계수 :           0\n",
            "0  0.035095\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000459\n",
            "결정계수 :           0\n",
            "0  0.029308\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999474\n",
            "결정계수 :           0\n",
            "0  0.023854\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :         0\n",
            "0  0.9995\n",
            "결정계수 :           0\n",
            "0  0.019506\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999582\n",
            "결정계수 :           0\n",
            "0  0.015003\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999721\n",
            "결정계수 :          0\n",
            "0  0.01034\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999921\n",
            "결정계수 :           0\n",
            "0  0.005513\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.92\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999815\n",
            "결정계수 :           0\n",
            "0  0.002233\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 138\n",
            "RMSE :           0\n",
            "0  1.058742\n",
            "결정계수 :           0\n",
            "0  0.486171\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 122\n",
            "RMSE :           0\n",
            "0  1.055475\n",
            "결정계수 :          0\n",
            "0  0.44389\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 103\n",
            "RMSE :           0\n",
            "0  1.049097\n",
            "결정계수 :           0\n",
            "0  0.400555\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 84\n",
            "RMSE :           0\n",
            "0  1.041403\n",
            "결정계수 :           0\n",
            "0  0.358133\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 73\n",
            "RMSE :           0\n",
            "0  1.035342\n",
            "결정계수 :           0\n",
            "0  0.318144\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 59\n",
            "RMSE :           0\n",
            "0  1.030619\n",
            "결정계수 :           0\n",
            "0  0.279813\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 49\n",
            "RMSE :           0\n",
            "0  1.025573\n",
            "결정계수 :           0\n",
            "0  0.243951\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.021814\n",
            "결정계수 :          0\n",
            "0  0.21139\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 29\n",
            "RMSE :           0\n",
            "0  1.018722\n",
            "결정계수 :          0\n",
            "0  0.18187\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.016135\n",
            "결정계수 :           0\n",
            "0  0.157102\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 20\n",
            "RMSE :           0\n",
            "0  1.014481\n",
            "결정계수 :           0\n",
            "0  0.133495\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.012971\n",
            "결정계수 :           0\n",
            "0  0.111859\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.011017\n",
            "결정계수 :           0\n",
            "0  0.092063\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 10\n",
            "RMSE :           0\n",
            "0  1.008798\n",
            "결정계수 :           0\n",
            "0  0.073941\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :          0\n",
            "0  1.00818\n",
            "결정계수 :           0\n",
            "0  0.062627\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.006898\n",
            "결정계수 :          0\n",
            "0  0.05372\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005094\n",
            "결정계수 :           0\n",
            "0  0.046498\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003087\n",
            "결정계수 :           0\n",
            "0  0.039408\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001589\n",
            "결정계수 :           0\n",
            "0  0.033751\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000145\n",
            "결정계수 :           0\n",
            "0  0.027882\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999472\n",
            "결정계수 :           0\n",
            "0  0.022756\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999512\n",
            "결정계수 :           0\n",
            "0  0.018346\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99961\n",
            "결정계수 :           0\n",
            "0  0.013778\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999766\n",
            "결정계수 :           0\n",
            "0  0.009047\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999983\n",
            "결정계수 :           0\n",
            "0  0.004149\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.93\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999739\n",
            "결정계수 :           0\n",
            "0  0.001516\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 137\n",
            "RMSE :          0\n",
            "0  1.05804\n",
            "결정계수 :           0\n",
            "0  0.484065\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 121\n",
            "RMSE :           0\n",
            "0  1.054797\n",
            "결정계수 :           0\n",
            "0  0.441405\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 102\n",
            "RMSE :           0\n",
            "0  1.048392\n",
            "결정계수 :          0\n",
            "0  0.39773\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 84\n",
            "RMSE :           0\n",
            "0  1.040804\n",
            "결정계수 :           0\n",
            "0  0.355104\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 72\n",
            "RMSE :           0\n",
            "0  1.034755\n",
            "결정계수 :           0\n",
            "0  0.314849\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 58\n",
            "RMSE :           0\n",
            "0  1.030069\n",
            "결정계수 :           0\n",
            "0  0.276389\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 49\n",
            "RMSE :           0\n",
            "0  1.024963\n",
            "결정계수 :           0\n",
            "0  0.240365\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.021299\n",
            "결정계수 :           0\n",
            "0  0.207898\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 28\n",
            "RMSE :           0\n",
            "0  1.018249\n",
            "결정계수 :           0\n",
            "0  0.178577\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.015781\n",
            "결정계수 :           0\n",
            "0  0.153732\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 19\n",
            "RMSE :           0\n",
            "0  1.014153\n",
            "결정계수 :           0\n",
            "0  0.130204\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.012643\n",
            "결정계수 :           0\n",
            "0  0.108751\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.010622\n",
            "결정계수 :           0\n",
            "0  0.088846\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 8\n",
            "RMSE :           0\n",
            "0  1.008459\n",
            "결정계수 :           0\n",
            "0  0.071636\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.007913\n",
            "결정계수 :          0\n",
            "0  0.06087\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.006601\n",
            "결정계수 :           0\n",
            "0  0.052147\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004685\n",
            "결정계수 :           0\n",
            "0  0.045008\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002767\n",
            "결정계수 :           0\n",
            "0  0.038142\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001276\n",
            "결정계수 :           0\n",
            "0  0.032411\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  0.999838\n",
            "결정계수 :           0\n",
            "0  0.026459\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999474\n",
            "결정계수 :           0\n",
            "0  0.021661\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999528\n",
            "결정계수 :           0\n",
            "0  0.017189\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999641\n",
            "결정계수 :           0\n",
            "0  0.012555\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999815\n",
            "결정계수 :           0\n",
            "0  0.007757\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999935\n",
            "결정계수 :           0\n",
            "0  0.003328\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.94\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999667\n",
            "결정계수 :         0\n",
            "0  0.0008\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 137\n",
            "RMSE :           0\n",
            "0  1.057343\n",
            "결정계수 :           0\n",
            "0  0.481977\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 120\n",
            "RMSE :           0\n",
            "0  1.054107\n",
            "결정계수 :          0\n",
            "0  0.43895\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 102\n",
            "RMSE :           0\n",
            "0  1.047652\n",
            "결정계수 :           0\n",
            "0  0.394932\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 84\n",
            "RMSE :           0\n",
            "0  1.040219\n",
            "결정계수 :           0\n",
            "0  0.352088\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 71\n",
            "RMSE :           0\n",
            "0  1.034182\n",
            "결정계수 :           0\n",
            "0  0.311573\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 58\n",
            "RMSE :           0\n",
            "0  1.029531\n",
            "결정계수 :           0\n",
            "0  0.272978\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 48\n",
            "RMSE :          0\n",
            "0  1.02441\n",
            "결정계수 :           0\n",
            "0  0.236815\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.020798\n",
            "결정계수 :           0\n",
            "0  0.204416\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 27\n",
            "RMSE :           0\n",
            "0  1.017781\n",
            "결정계수 :           0\n",
            "0  0.175346\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 23\n",
            "RMSE :           0\n",
            "0  1.015428\n",
            "결정계수 :           0\n",
            "0  0.150457\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 19\n",
            "RMSE :           0\n",
            "0  1.013847\n",
            "결정계수 :           0\n",
            "0  0.126974\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.012325\n",
            "결정계수 :           0\n",
            "0  0.105657\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.010237\n",
            "결정계수 :           0\n",
            "0  0.085642\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 8\n",
            "RMSE :           0\n",
            "0  1.008148\n",
            "결정계수 :           0\n",
            "0  0.069431\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.007652\n",
            "결정계수 :           0\n",
            "0  0.059117\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :          0\n",
            "0  1.00631\n",
            "결정계수 :           0\n",
            "0  0.050577\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004283\n",
            "결정계수 :           0\n",
            "0  0.043523\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002455\n",
            "결정계수 :           0\n",
            "0  0.036883\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000969\n",
            "결정계수 :           0\n",
            "0  0.031073\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  0.999538\n",
            "결정계수 :          0\n",
            "0  0.02504\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999478\n",
            "결정계수 :           0\n",
            "0  0.020569\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999548\n",
            "결정계수 :           0\n",
            "0  0.016034\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999677\n",
            "결정계수 :           0\n",
            "0  0.011335\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999867\n",
            "결정계수 :           0\n",
            "0  0.006469\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :          0\n",
            "0  0.99986\n",
            "결정계수 :          0\n",
            "0  0.00265\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.95\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999598\n",
            "결정계수 :           0\n",
            "0  0.000085\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 136\n",
            "RMSE :           0\n",
            "0  1.056658\n",
            "결정계수 :           0\n",
            "0  0.479903\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 120\n",
            "RMSE :           0\n",
            "0  1.053434\n",
            "결정계수 :           0\n",
            "0  0.436514\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 101\n",
            "RMSE :           0\n",
            "0  1.046924\n",
            "결정계수 :           0\n",
            "0  0.392163\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 84\n",
            "RMSE :           0\n",
            "0  1.039648\n",
            "결정계수 :           0\n",
            "0  0.349085\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 71\n",
            "RMSE :          0\n",
            "0  1.03362\n",
            "결정계수 :          0\n",
            "0  0.30833\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 58\n",
            "RMSE :           0\n",
            "0  1.029007\n",
            "결정계수 :           0\n",
            "0  0.269579\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 48\n",
            "RMSE :           0\n",
            "0  1.023904\n",
            "결정계수 :           0\n",
            "0  0.233297\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 39\n",
            "RMSE :           0\n",
            "0  1.020311\n",
            "결정계수 :           0\n",
            "0  0.200945\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 25\n",
            "RMSE :           0\n",
            "0  1.017306\n",
            "결정계수 :          0\n",
            "0  0.17221\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 23\n",
            "RMSE :           0\n",
            "0  1.015085\n",
            "결정계수 :           0\n",
            "0  0.147203\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 18\n",
            "RMSE :          0\n",
            "0  1.01353\n",
            "결정계수 :           0\n",
            "0  0.123806\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 15\n",
            "RMSE :           0\n",
            "0  1.012016\n",
            "결정계수 :           0\n",
            "0  0.102576\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 13\n",
            "RMSE :           0\n",
            "0  1.009841\n",
            "결정계수 :           0\n",
            "0  0.082525\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :          0\n",
            "0  1.00806\n",
            "결정계수 :           0\n",
            "0  0.067541\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.007397\n",
            "결정계수 :          0\n",
            "0  0.05737\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005948\n",
            "결정계수 :           0\n",
            "0  0.049134\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003889\n",
            "결정계수 :           0\n",
            "0  0.042041\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002149\n",
            "결정계수 :           0\n",
            "0  0.035628\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000669\n",
            "결정계수 :           0\n",
            "0  0.029739\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999461\n",
            "결정계수 :           0\n",
            "0  0.023914\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999487\n",
            "결정계수 :           0\n",
            "0  0.019479\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999571\n",
            "결정계수 :           0\n",
            "0  0.014882\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999716\n",
            "결정계수 :           0\n",
            "0  0.010118\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999923\n",
            "결정계수 :           0\n",
            "0  0.005184\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.96\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999787\n",
            "결정계수 :           0\n",
            "0  0.001973\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 136\n",
            "RMSE :           0\n",
            "0  1.055981\n",
            "결정계수 :           0\n",
            "0  0.477847\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 120\n",
            "RMSE :           0\n",
            "0  1.052774\n",
            "결정계수 :           0\n",
            "0  0.434092\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 101\n",
            "RMSE :           0\n",
            "0  1.046211\n",
            "결정계수 :           0\n",
            "0  0.389412\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 83\n",
            "RMSE :          0\n",
            "0  1.03905\n",
            "결정계수 :           0\n",
            "0  0.346109\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 70\n",
            "RMSE :           0\n",
            "0  1.033051\n",
            "결정계수 :           0\n",
            "0  0.305109\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 58\n",
            "RMSE :           0\n",
            "0  1.028495\n",
            "결정계수 :           0\n",
            "0  0.266192\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 47\n",
            "RMSE :           0\n",
            "0  1.023393\n",
            "결정계수 :           0\n",
            "0  0.229821\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 38\n",
            "RMSE :           0\n",
            "0  1.019843\n",
            "결정계수 :           0\n",
            "0  0.197515\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 25\n",
            "RMSE :           0\n",
            "0  1.016856\n",
            "결정계수 :           0\n",
            "0  0.169134\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 22\n",
            "RMSE :           0\n",
            "0  1.014775\n",
            "결정계수 :        0\n",
            "0  0.144\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.013227\n",
            "결정계수 :           0\n",
            "0  0.120717\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.011677\n",
            "결정계수 :           0\n",
            "0  0.099563\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 12\n",
            "RMSE :           0\n",
            "0  1.009401\n",
            "결정계수 :           0\n",
            "0  0.079624\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.007981\n",
            "결정계수 :           0\n",
            "0  0.065663\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.007148\n",
            "결정계수 :           0\n",
            "0  0.055627\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005558\n",
            "결정계수 :           0\n",
            "0  0.047749\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003501\n",
            "결정계수 :           0\n",
            "0  0.040563\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :          0\n",
            "0  1.00185\n",
            "결정계수 :           0\n",
            "0  0.034375\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000375\n",
            "결정계수 :           0\n",
            "0  0.028408\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999459\n",
            "결정계수 :           0\n",
            "0  0.022887\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999498\n",
            "결정계수 :           0\n",
            "0  0.018392\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999598\n",
            "결정계수 :           0\n",
            "0  0.013732\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999758\n",
            "결정계수 :           0\n",
            "0  0.008904\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999983\n",
            "결정계수 :           0\n",
            "0  0.003902\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.97\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999717\n",
            "결정계수 :           0\n",
            "0  0.001297\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 136\n",
            "RMSE :           0\n",
            "0  1.055315\n",
            "결정계수 :           0\n",
            "0  0.475805\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 120\n",
            "RMSE :           0\n",
            "0  1.052127\n",
            "결정계수 :           0\n",
            "0  0.431685\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 101\n",
            "RMSE :           0\n",
            "0  1.045511\n",
            "결정계수 :           0\n",
            "0  0.386674\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 83\n",
            "RMSE :          0\n",
            "0  1.03841\n",
            "결정계수 :           0\n",
            "0  0.343166\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 70\n",
            "RMSE :           0\n",
            "0  1.032472\n",
            "결정계수 :           0\n",
            "0  0.301912\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 57\n",
            "RMSE :           0\n",
            "0  1.027991\n",
            "결정계수 :           0\n",
            "0  0.262818\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 45\n",
            "RMSE :           0\n",
            "0  1.022877\n",
            "결정계수 :           0\n",
            "0  0.226393\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 37\n",
            "RMSE :           0\n",
            "0  1.019394\n",
            "결정계수 :           0\n",
            "0  0.194142\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 25\n",
            "RMSE :           0\n",
            "0  1.016418\n",
            "결정계수 :           0\n",
            "0  0.166068\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.014489\n",
            "결정계수 :           0\n",
            "0  0.140873\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :           0\n",
            "0  1.012939\n",
            "결정계수 :           0\n",
            "0  0.117677\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.011294\n",
            "결정계수 :           0\n",
            "0  0.096636\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 12\n",
            "RMSE :           0\n",
            "0  1.008953\n",
            "결정계수 :           0\n",
            "0  0.076836\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.007907\n",
            "결정계수 :           0\n",
            "0  0.063791\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.006893\n",
            "결정계수 :           0\n",
            "0  0.053979\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.005175\n",
            "결정계수 :           0\n",
            "0  0.046367\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.003121\n",
            "결정계수 :           0\n",
            "0  0.039089\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001556\n",
            "결정계수 :           0\n",
            "0  0.033126\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000087\n",
            "결정계수 :           0\n",
            "0  0.027081\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999459\n",
            "결정계수 :           0\n",
            "0  0.021862\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999513\n",
            "결정계수 :           0\n",
            "0  0.017308\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999627\n",
            "결정계수 :           0\n",
            "0  0.012586\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999804\n",
            "결정계수 :           0\n",
            "0  0.007693\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999921\n",
            "결정계수 :           0\n",
            "0  0.003206\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.98\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :          0\n",
            "0  0.99965\n",
            "결정계수 :           0\n",
            "0  0.000622\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 136\n",
            "RMSE :           0\n",
            "0  1.054668\n",
            "결정계수 :           0\n",
            "0  0.473776\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 120\n",
            "RMSE :           0\n",
            "0  1.051494\n",
            "결정계수 :           0\n",
            "0  0.429291\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 100\n",
            "RMSE :           0\n",
            "0  1.044821\n",
            "결정계수 :           0\n",
            "0  0.383951\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 82\n",
            "RMSE :           0\n",
            "0  1.037783\n",
            "결정계수 :           0\n",
            "0  0.340236\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 70\n",
            "RMSE :           0\n",
            "0  1.031908\n",
            "결정계수 :           0\n",
            "0  0.298731\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 55\n",
            "RMSE :           0\n",
            "0  1.027474\n",
            "결정계수 :           0\n",
            "0  0.259486\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 44\n",
            "RMSE :           0\n",
            "0  1.022424\n",
            "결정계수 :           0\n",
            "0  0.223087\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 37\n",
            "RMSE :           0\n",
            "0  1.018959\n",
            "결정계수 :           0\n",
            "0  0.190835\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.016055\n",
            "결정계수 :           0\n",
            "0  0.163054\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.014197\n",
            "결정계수 :           0\n",
            "0  0.137855\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :          0\n",
            "0  1.01266\n",
            "결정계수 :           0\n",
            "0  0.114651\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.010921\n",
            "결정계수 :           0\n",
            "0  0.093723\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 11\n",
            "RMSE :           0\n",
            "0  1.008652\n",
            "결정계수 :         0\n",
            "0  0.0742\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 7\n",
            "RMSE :           0\n",
            "0  1.007837\n",
            "결정계수 :           0\n",
            "0  0.061926\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.006619\n",
            "결정계수 :           0\n",
            "0  0.052529\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004798\n",
            "결정계수 :          0\n",
            "0  0.04499\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002789\n",
            "결정계수 :           0\n",
            "0  0.037772\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.001269\n",
            "결정계수 :          0\n",
            "0  0.03188\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  0.999806\n",
            "결정계수 :           0\n",
            "0  0.025757\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999463\n",
            "결정계수 :          0\n",
            "0  0.02084\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999531\n",
            "결정계수 :           0\n",
            "0  0.016226\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99966\n",
            "결정계수 :           0\n",
            "0  0.011442\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999853\n",
            "결정계수 :           0\n",
            "0  0.006484\n",
            "\n",
            "알파 값 :       0\n",
            "0  0.99\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999851\n",
            "결정계수 :           0\n",
            "0  0.002568\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 136\n",
            "RMSE :           0\n",
            "0  1.054034\n",
            "결정계수 :           0\n",
            "0  0.471761\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 120\n",
            "RMSE :           0\n",
            "0  1.050872\n",
            "결정계수 :           0\n",
            "0  0.426911\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 97\n",
            "RMSE :          0\n",
            "0  1.04412\n",
            "결정계수 :           0\n",
            "0  0.381254\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 82\n",
            "RMSE :           0\n",
            "0  1.037163\n",
            "결정계수 :           0\n",
            "0  0.337329\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 69\n",
            "RMSE :           0\n",
            "0  1.031332\n",
            "결정계수 :           0\n",
            "0  0.295588\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 54\n",
            "RMSE :           0\n",
            "0  1.026959\n",
            "결정계수 :           0\n",
            "0  0.256228\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 43\n",
            "RMSE :           0\n",
            "0  1.021972\n",
            "결정계수 :           0\n",
            "0  0.219858\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 36\n",
            "RMSE :          0\n",
            "0  1.01854\n",
            "결정계수 :           0\n",
            "0  0.187541\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 24\n",
            "RMSE :           0\n",
            "0  1.015716\n",
            "결정계수 :           0\n",
            "0  0.160058\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 21\n",
            "RMSE :           0\n",
            "0  1.013915\n",
            "결정계수 :           0\n",
            "0  0.134848\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 17\n",
            "RMSE :          0\n",
            "0  1.01239\n",
            "결정계수 :           0\n",
            "0  0.111637\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 14\n",
            "RMSE :           0\n",
            "0  1.010558\n",
            "결정계수 :           0\n",
            "0  0.090822\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 10\n",
            "RMSE :           0\n",
            "0  1.008315\n",
            "결정계수 :           0\n",
            "0  0.071806\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 6\n",
            "RMSE :           0\n",
            "0  1.007681\n",
            "결정계수 :           0\n",
            "0  0.060195\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 5\n",
            "RMSE :           0\n",
            "0  1.006351\n",
            "결정계수 :           0\n",
            "0  0.051081\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 4\n",
            "RMSE :           0\n",
            "0  1.004428\n",
            "결정계수 :           0\n",
            "0  0.043617\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.002502\n",
            "결정계수 :           0\n",
            "0  0.036604\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :           0\n",
            "0  1.000987\n",
            "결정계수 :           0\n",
            "0  0.030638\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 3\n",
            "RMSE :          0\n",
            "0  0.99953\n",
            "결정계수 :           0\n",
            "0  0.024436\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :          0\n",
            "0  0.99947\n",
            "결정계수 :           0\n",
            "0  0.019821\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999552\n",
            "결정계수 :           0\n",
            "0  0.015147\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999696\n",
            "결정계수 :           0\n",
            "0  0.010302\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 2\n",
            "RMSE :           0\n",
            "0  0.999906\n",
            "결정계수 :           0\n",
            "0  0.005279\n",
            "\n",
            "알파 값 :      0\n",
            "0  1.0\n",
            "사용된 변수 개수 : 1\n",
            "RMSE :           0\n",
            "0  0.999783\n",
            "결정계수 :           0\n",
            "0  0.001931\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsUTH9_cq2Be"
      },
      "source": [
        "# 이 테이블에서 l1_ratio는 제약의 가중치라고 볼 수있다.\n",
        "만약 l1_ratio=1이라면 오직 L1 패널티이며, l1_ratio=0이라면 오직 L2패널티만이 존재한다. 이에 알파값과 l1_ratio값을 변화시키면서 살펴본 결과 다음과 같은 테이블을 얻을 수 있었다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "A73lmMETSn7S",
        "outputId": "a9802933-f0f0-404e-a2d4-35899eff930e"
      },
      "source": [
        "ela=elastic_set.copy()\n",
        "ela.columns=['alpha','l1_ratio','number','rmse','r2']\n",
        "ela=ela.reset_index()\n",
        "ela=ela.drop(['index'],axis=1)\n",
        "ela"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>l1_ratio</th>\n",
              "      <th>number</th>\n",
              "      <th>rmse</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>170</td>\n",
              "      <td>5.373803</td>\n",
              "      <td>0.942649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>170</td>\n",
              "      <td>5.373803</td>\n",
              "      <td>0.942649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>170</td>\n",
              "      <td>5.373803</td>\n",
              "      <td>0.942649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>170</td>\n",
              "      <td>5.373803</td>\n",
              "      <td>0.942649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>170</td>\n",
              "      <td>5.373803</td>\n",
              "      <td>0.942649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5944</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.20</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999470</td>\n",
              "      <td>0.019821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5945</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999552</td>\n",
              "      <td>0.015147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5946</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.22</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999696</td>\n",
              "      <td>0.010302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5947</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>2</td>\n",
              "      <td>0.999906</td>\n",
              "      <td>0.005279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5948</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999783</td>\n",
              "      <td>0.001931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5949 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      alpha  l1_ratio  number      rmse        r2\n",
              "0       0.0      0.01     170  5.373803  0.942649\n",
              "1       0.0      0.02     170  5.373803  0.942649\n",
              "2       0.0      0.03     170  5.373803  0.942649\n",
              "3       0.0      0.04     170  5.373803  0.942649\n",
              "4       0.0      0.05     170  5.373803  0.942649\n",
              "...     ...       ...     ...       ...       ...\n",
              "5944    1.0      0.20       2  0.999470  0.019821\n",
              "5945    1.0      0.21       2  0.999552  0.015147\n",
              "5946    1.0      0.22       2  0.999696  0.010302\n",
              "5947    1.0      0.23       2  0.999906  0.005279\n",
              "5948    1.0      0.24       1  0.999783  0.001931\n",
              "\n",
              "[5949 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceu0jq2xrO2x"
      },
      "source": [
        "# 라쏘 선택법의 rsme, 결정계수 그래프\n",
        "\n",
        "파란선이 rmsw, 노란선이 결정계수이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "mhN0gf0mccGk",
        "outputId": "212f3923-bf7d-40a9-8f54-bcc62a429f9f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lasso_set['rmse'])\n",
        "plt.plot(lasso_set['r2'])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5643a20650>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJhgIw2rrz_T"
      },
      "source": [
        "# 엘라스틱 넷의 rmse, 결정계수 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "zmRHKQHFddRd",
        "outputId": "cdfb95bc-59d4-4a04-8a57-db2e51c3961e"
      },
      "source": [
        "plt.plot(ela[['rmse','r2']])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f56437c1ad0>,\n",
              " <matplotlib.lines.Line2D at 0x7f56437c1910>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-3LNpFBsS1X"
      },
      "source": [
        "# 엘라스틱넷의 사용된 변수개수 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "RqygCNIPsKvc",
        "outputId": "4898ca70-24a5-44c9-cda6-508290b5576a"
      },
      "source": [
        "plt.plot(ela['number'])"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5643958b10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSHlrl4BrWR5"
      },
      "source": [
        "# RQ1 결론\n",
        "\n",
        "전진선택법, 후진소거법, 단계선택법이 세가지 중에서 단계선택법이 RMSE도 가장낮고, 사용하는 변수도 적고, 결정계수도 준수한 모습을 보여주었다.\n",
        "\n",
        "만약 위 데이터셋처럼 데이터의 차원이 크고 결정계수가 아닌 RMSE를 최소화 하는것이 목표라면 단계선택법을 선택해야하며, 결정계수를 높이기 위한 목적으로 모델을 훈련시킨다면 전진선택법을 사용해야 한다.\n",
        "\n",
        "또한, 라쏘, 엘라스틱 넷의 경우는 위에 언급한 세 가지 방법들보다 뛰어난 모습을 보여준다. 하지만 이때, 알파값의 세밀한 조정이 필요하며 특히 엘라스틱넷의 경우는 제약 항이 두개여서 시간적인 비용이 더 소모가 된다. 하지만 그래프에서 볼 수 있듯이, RMSE가 낮고 결정계수가 높은 구간이 엘라스틱넷에서는 존재한다.\n",
        "\n",
        "그러므로 적절한 알파값과 L1_RATIO값을 위에 써놓은 코딩을 통해 도출하여서 결과적으로는 엘라스틱 넷이 모든 방법들중에 시간이라는 비용은 많이 들지만 가장 설명력 높은 모델이며, 가장 데이터셋의 정보를 많이 활용하는 유연한 모델임을 알 수 있었다. 그렇기 때문에 이에 따른 변수를 선택하고 머신러닝 모델에 활용하는 것은 유연함과 동시에 효율적인 변수선택법이 될 수 있음을 알 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZXY8-BBsvbi"
      },
      "source": [
        "# RQ2. 타이타닉호 승객 데이터를 활용하여 어떤 유형의 승객의 생존율이 높은지 분석하기 위해서 관련성이 높은 변수는 무엇일까?\n",
        "\n",
        "캐글의 가장 유명한 데이터셋중 하나인 타이타닉 데이터를 활용해서 어떤 승객이 생존율이 높은지 예측하는 과정이다.\n",
        "\n",
        "이를 위해서 어떤 변수를 선택해야 효율적일지 알아보기 위해 각 변수와 Survived라는 타겟변수간의 관계를 살펴본다.\n",
        "\n",
        "이에 연관이 없는 변수는 제거하고, 연관이 있는 변수는 활용하여 예측 및 분석에 이용할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFadc1h_tigL"
      },
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "Pclass - 승객의 좌석 등급(범주형)\n",
        "\n",
        "SibSp- 형제 자매 수(이산형), \n",
        "\n",
        "Parch - 부모와 자식 수(이산형)\n",
        "\n",
        "Cabin - 좌석 번호(혼합)\n",
        "\n",
        "Embarked - 승선 장소(범주형, 3가지 타입)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "4QqXZOmSd797",
        "outputId": "5e7bf468-bbfb-4355-f3b1-a85e46decccc"
      },
      "source": [
        "train=pd.read_csv('./train (2).csv')\n",
        "train"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0              1         0       3  ...   7.2500   NaN         S\n",
              "1              2         1       1  ...  71.2833   C85         C\n",
              "2              3         1       3  ...   7.9250   NaN         S\n",
              "3              4         1       1  ...  53.1000  C123         S\n",
              "4              5         0       3  ...   8.0500   NaN         S\n",
              "..           ...       ...     ...  ...      ...   ...       ...\n",
              "886          887         0       2  ...  13.0000   NaN         S\n",
              "887          888         1       1  ...  30.0000   B42         S\n",
              "888          889         0       3  ...  23.4500   NaN         S\n",
              "889          890         1       1  ...  30.0000  C148         C\n",
              "890          891         0       3  ...   7.7500   NaN         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMjIlsx4tlkg"
      },
      "source": [
        "# 범주형 데이터만 모아주기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "ekrw7ntpfS15",
        "outputId": "0efb1076-348b-4492-e847-06a817ea2cac"
      },
      "source": [
        "train=train[['Survived','Pclass','Sex','Embarked']]\n",
        "train"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass     Sex Embarked\n",
              "0           0       3    male        S\n",
              "1           1       1  female        C\n",
              "2           1       3  female        S\n",
              "3           1       1  female        S\n",
              "4           0       3    male        S\n",
              "..        ...     ...     ...      ...\n",
              "886         0       2    male        S\n",
              "887         1       1  female        S\n",
              "888         0       3  female        S\n",
              "889         1       1    male        C\n",
              "890         0       3    male        Q\n",
              "\n",
              "[891 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSVRQWNvtoKy"
      },
      "source": [
        "# 데이터 결측값 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSaWWqV1fqW_",
        "outputId": "fbfbd0d0-0dd9-4d31-cf87-22ff722efc17"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived    0\n",
              "Pclass      0\n",
              "Sex         0\n",
              "Embarked    2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8uZ6rI4tp0i"
      },
      "source": [
        "# 결측값 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "UHGNb35If2yd",
        "outputId": "77270cf2-f5c1-4b68-8ab9-2af44ed229f2"
      },
      "source": [
        "train=train.dropna()\n",
        "train"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>889 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass     Sex Embarked\n",
              "0           0       3    male        S\n",
              "1           1       1  female        C\n",
              "2           1       3  female        S\n",
              "3           1       1  female        S\n",
              "4           0       3    male        S\n",
              "..        ...     ...     ...      ...\n",
              "886         0       2    male        S\n",
              "887         1       1  female        S\n",
              "888         0       3  female        S\n",
              "889         1       1    male        C\n",
              "890         0       3    male        Q\n",
              "\n",
              "[889 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmO5VjvRtrO5"
      },
      "source": [
        "# 데이터 리인덱싱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "_aCK1IdsgOCq",
        "outputId": "4c4720c2-aacd-466c-82aa-826b4ea2e47f"
      },
      "source": [
        "train=train.reset_index()\n",
        "train=train.drop(['index'],axis=1)\n",
        "train"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>889 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass     Sex Embarked\n",
              "0           0       3    male        S\n",
              "1           1       1  female        C\n",
              "2           1       3  female        S\n",
              "3           1       1  female        S\n",
              "4           0       3    male        S\n",
              "..        ...     ...     ...      ...\n",
              "884         0       2    male        S\n",
              "885         1       1  female        S\n",
              "886         0       3  female        S\n",
              "887         1       1    male        C\n",
              "888         0       3    male        Q\n",
              "\n",
              "[889 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tH7wZEJttc0"
      },
      "source": [
        "# 범주형 데이터를 숫자로 변환해주기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "IO4GWynkf47I",
        "outputId": "a1851301-0fe2-40d0-9081-5e7a845d9414"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "encoder = OrdinalEncoder()\n",
        "category=encoder.fit_transform(train[['Sex','Embarked']])\n",
        "category=pd.DataFrame(category)\n",
        "category.columns=['Sex','Embarked']\n",
        "category"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>889 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sex  Embarked\n",
              "0    1.0       2.0\n",
              "1    0.0       0.0\n",
              "2    0.0       2.0\n",
              "3    0.0       2.0\n",
              "4    1.0       2.0\n",
              "..   ...       ...\n",
              "884  1.0       2.0\n",
              "885  0.0       2.0\n",
              "886  0.0       2.0\n",
              "887  1.0       0.0\n",
              "888  1.0       1.0\n",
              "\n",
              "[889 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "4bP8CjPPgA6-",
        "outputId": "fad2c3c1-b75d-4b4d-93e6-1109b3bff85a"
      },
      "source": [
        "train['Sex']=category['Sex']\n",
        "train['Embarked']=category['Embarked']\n",
        "train"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>884</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>889 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass  Sex  Embarked\n",
              "0           0       3  1.0       2.0\n",
              "1           1       1  0.0       0.0\n",
              "2           1       3  0.0       2.0\n",
              "3           1       1  0.0       2.0\n",
              "4           0       3  1.0       2.0\n",
              "..        ...     ...  ...       ...\n",
              "884         0       2  1.0       2.0\n",
              "885         1       1  0.0       2.0\n",
              "886         0       3  0.0       2.0\n",
              "887         1       1  1.0       0.0\n",
              "888         0       3  1.0       1.0\n",
              "\n",
              "[889 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh3uKue-twaO"
      },
      "source": [
        "# 카이제곱 검정을 위한 분할표 생성 및, 카이제곱 검정 실시\n",
        "\n",
        "귀무가설 : 두 변수는 독립이다.(연관이 없다.)\n",
        "\n",
        "대립가설 : 두 변수는 종속이다.(연관이 있다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1fAmY1nucbJ"
      },
      "source": [
        "#승객의 좌석 등급 & Survived"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym1B9naBgrP-",
        "outputId": "bbcc25d8-bf2f-41bf-c4b2-fea09c19b35e"
      },
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "chi_data=pd.crosstab(index=train.Pclass, columns=train.Survived,values=train.Survived, aggfunc=pd.value_counts )\n",
        "chi, p, dof, expected = chi2_contingency(chi_data)\n",
        "if p <0.05:\n",
        "  print('Survived and Pclass')\n",
        "  print()\n",
        "  print(f\"chi 스퀘어 값: {chi}\",\n",
        "      f\"p-value (0.05): {p}\",\n",
        "      f\"자유도 수: {dof}\",\n",
        "      f\"기대값: \\n{pd.DataFrame(expected)}\",\n",
        "      f\"측정값: \\n{chi_data}\", sep = \"\\n\" )\n",
        "  print('p-value가 0.05 이하 이므로, 귀무가설을 기각한다. 즉, 생존과 Pclass는 관계가 있다.')\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Survived and Pclass\n",
            "\n",
            "chi 스퀘어 값: 100.98040726128336\n",
            "p-value (0.05): 1.1813624785477922e-22\n",
            "자유도 수: 2\n",
            "기대값: \n",
            "            0           1\n",
            "0  132.155231   81.844769\n",
            "1  113.628796   70.371204\n",
            "2  303.215973  187.784027\n",
            "측정값: \n",
            "Survived    0    1\n",
            "Pclass            \n",
            "1          80  134\n",
            "2          97   87\n",
            "3         372  119\n",
            "p-value가 0.05 이하 이므로, 귀무가설을 기각한다. 즉, 생존과 Pclass는 관계가 있다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6ye1vgLuiZ4"
      },
      "source": [
        "#승객의 성별 & Survived"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2LsIvz5gtjB",
        "outputId": "b2385d7e-a08c-47f7-dd7f-a31f42972e2f"
      },
      "source": [
        "chi_data=pd.crosstab(index=train.Sex, columns=train.Survived,values=train.Survived, aggfunc=pd.value_counts )\n",
        "chi, p, dof, expected = chi2_contingency(chi_data)\n",
        "if p <0.05:\n",
        "  print('Survived and Sex')\n",
        "  print()\n",
        "  print(f\"chi 스퀘어 값: {chi}\",\n",
        "      f\"p-value (0.05): {p}\",\n",
        "      f\"자유도 수: {dof}\",\n",
        "      f\"기대값: \\n{pd.DataFrame(expected)}\",\n",
        "      f\"측정값: \\n{chi_data}\", sep = \"\\n\" )\n",
        "  print('p-value가 0.05 이하 이므로, 귀무가설을 기각한다. 즉, 생존과 성별은 관계가 있다.')\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Survived and Sex\n",
            "\n",
            "chi 스퀘어 값: 258.4266104463763\n",
            "p-value (0.05): 3.7799096665576e-58\n",
            "자유도 수: 1\n",
            "기대값: \n",
            "            0           1\n",
            "0  192.674916  119.325084\n",
            "1  356.325084  220.674916\n",
            "측정값: \n",
            "Survived    0    1\n",
            "Sex               \n",
            "0.0        81  231\n",
            "1.0       468  109\n",
            "p-value가 0.05 이하 이므로, 귀무가설을 기각한다. 즉, 생존과 성별은 관계가 있다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1B6l9uIuqcL"
      },
      "source": [
        "#승객의 승선역 & Survived"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px4XXnnphoDx",
        "outputId": "742a3ec3-7de9-4a75-84d1-b9965fad6c2a"
      },
      "source": [
        "chi_data=pd.crosstab(index=train.Embarked, columns=train.Survived,values=train.Survived, aggfunc=pd.value_counts)\n",
        "chi_data=chi_data.fillna(0)\n",
        "chi, p, dof, expected = chi2_contingency(chi_data)\n",
        "if p <0.05:\n",
        "  print('Survived and Embarked')\n",
        "  print()\n",
        "  print(f\"chi 스퀘어 값: {chi}\",\n",
        "      f\"p-value (0.05): {p}\",\n",
        "      f\"자유도 수: {dof}\",\n",
        "      f\"기대값: \\n{pd.DataFrame(expected)}\",\n",
        "      f\"측정값: \\n{chi_data}\", sep = \"\\n\" )\n",
        "  print('p-value가 0.05 이하 이므로, 귀무가설을 기각한다. 즉, 생존과 승선장소간의 관계가 있다.')\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Survived and Embarked\n",
            "\n",
            "chi 스퀘어 값: 26.48914983923762\n",
            "p-value (0.05): 1.769922284120912e-06\n",
            "자유도 수: 2\n",
            "기대값: \n",
            "            0           1\n",
            "0  103.748031   64.251969\n",
            "1   47.551181   29.448819\n",
            "2  397.700787  246.299213\n",
            "측정값: \n",
            "Survived    0    1\n",
            "Embarked          \n",
            "0.0        75   93\n",
            "1.0        47   30\n",
            "2.0       427  217\n",
            "p-value가 0.05 이하 이므로, 귀무가설을 기각한다. 즉, 생존과 승선장소간의 관계가 있다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL2kqbBOuw_5"
      },
      "source": [
        "# 결론적으로는 Pclass, Sex, Embakred는 모두 Survived와 관계가 있기 때문에 다음의 예측및 분석에서 이 변수들을 활용할 수 있다.\n",
        "\n",
        "또한, 성별의 경우에는 p-value가 가장 낮게 나왔는데 이는 귀무가설을 지지하는 정도가 가장 약하다는 것이므로, 성별이 특히 생존과 관련이 높았음을 알 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr1IpJYtyS2x"
      },
      "source": [
        "# Team Review\n",
        "\n",
        "이번 실습을 진행하면서 가장 흥미로웠던 것은 170개정도의 변수가 오히려 몇몇개의 변수가 있었을 때보다 설명력도 낮고 효율적이지 않은 모델인것을 직접 겪게 되니 변수선택은 데이터 분석의 시작에 있어서 가장 중요한 부분이라고 느끼게 되었다. 특히, 전진선택법 부터 엘라스틱 넷 변수선택법 까지 그리고 이 외에도 다양한 변수선택법이 있지만, 어떤 데이터셋을 활용하고 어떠한 목표를 갖고, 어떠한 상황속에서 분석을 실시하느냐에 따라서 과정과 결과가 많이 달라질 것 같다고 느꼈다. 그렇기 때문에 다른 변수선택법의 탐구의 필요성도 절실히 느끼게 되었다.\n",
        "\n",
        "카이제곱검정의 경우에는 비교적 단순한 편이었지만, 범주형을 수치화시켜서 자료간의 독립성 검정여부를 따지는것이 가장 흥미로웠다.성별이 생존에 가장 영향을 주었다는 결과에서, 실제로도 타이타닉 침몰사건과 같은 위급상황이면 노약자와 여성분들을 우선순위로 챙기는 상황이 많기 때문에 어찌보면 당연한 결과라고도 할 수 있지만 직접 분석을 통해 이를 밝혀냈다는 점이 가장 인상깊기도 했다.\n",
        "카이제곱검정 뿐만이 아니라, 오즈비 검정, 로짓 모형 등과같은 분석도 많이 경험을 해보고 싶다는 생각도 들었다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir-xZdFLu8fQ"
      },
      "source": [
        "# 데이터 출처 : Kaggle\n",
        "\n",
        "변수선택데이터 : Don't overfit!!, Kaggle\n",
        "카이제곱검정데이터 : Titanic, Kaggle"
      ]
    }
  ]
}